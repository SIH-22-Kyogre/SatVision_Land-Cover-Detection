{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing few libraries\nimport os\nimport shutil\nimport random\nfrom tqdm import tqdm\n\nimport numpy as np\nimport pandas as pd\n\nimport PIL\nimport seaborn as sns\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-21T11:33:29.552053Z","iopub.execute_input":"2022-08-21T11:33:29.552287Z","iopub.status.idle":"2022-08-21T11:33:30.746916Z","shell.execute_reply.started":"2022-08-21T11:33:29.552260Z","shell.execute_reply":"2022-08-21T11:33:30.746258Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"DATASET = \"../input/2750\"\n\nLABELS = os.listdir(DATASET)\nprint(LABELS)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:33:52.169592Z","iopub.execute_input":"2022-08-21T11:33:52.169882Z","iopub.status.idle":"2022-08-21T11:33:52.180464Z","shell.execute_reply.started":"2022-08-21T11:33:52.169853Z","shell.execute_reply":"2022-08-21T11:33:52.179355Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"['SeaLake', 'Highway', 'River', 'Pasture', 'Industrial', 'Residential', 'PermanentCrop', 'AnnualCrop', 'Forest', 'HerbaceousVegetation']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data Preprocessing\n\n70/30 split - 70% of the data is used for training the model, 30% is used for testing","metadata":{}},{"cell_type":"code","source":"import re\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = '../working/training'\nTEST_DIR = '../working/testing'\nBATCH_SIZE = 64\nNUM_CLASSES=len(LABELS)\nINPUT_SHAPE = (64, 64, 3)\nCLASS_MODE = 'categorical'\n\n# create training and testing directories\nfor path in (TRAIN_DIR, TEST_DIR):\n    if not os.path.exists(path):\n        os.mkdir(path)\n\n# create class label subdirectories in train and test\nfor l in LABELS:\n    \n    if not os.path.exists(os.path.join(TRAIN_DIR, l)):\n        os.mkdir(os.path.join(TRAIN_DIR, l))\n\n    if not os.path.exists(os.path.join(TEST_DIR, l)):\n        os.mkdir(os.path.join(TEST_DIR, l))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:33:58.066646Z","iopub.execute_input":"2022-08-21T11:33:58.066919Z","iopub.status.idle":"2022-08-21T11:33:58.077368Z","shell.execute_reply.started":"2022-08-21T11:33:58.066891Z","shell.execute_reply":"2022-08-21T11:33:58.076647Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# map each image path to their class label in 'data'\ndata = {}\n\nfor l in LABELS:\n    for img in os.listdir(DATASET+'/'+l):\n        data.update({os.path.join(DATASET, l, img): l})\n\nX = pd.Series(list(data.keys()))\ny = pd.get_dummies(pd.Series(data.values()))\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=69)\n\n# split the list of image paths\nfor train_idx, test_idx in split.split(X, y):\n    \n    train_paths = X[train_idx]\n    test_paths = X[test_idx]\n\n    # define a new path for each image depending on training or testing\n    new_train_paths = [re.sub('\\.\\.\\/input\\/2750', '../working/training', i) for i in train_paths]\n    new_test_paths = [re.sub('\\.\\.\\/input\\/2750', '../working/testing', i) for i in test_paths]\n\n    train_path_map = list((zip(train_paths, new_train_paths)))\n    test_path_map = list((zip(test_paths, new_test_paths)))\n    \n    # move the files\n    print(\"moving training files..\")\n    for i in tqdm(train_path_map):\n        if not os.path.exists(i[1]):\n            if not os.path.exists(re.sub('training', 'testing', i[1])):\n                shutil.copy(i[0], i[1])\n    \n    print(\"moving testing files..\")\n    for i in tqdm(test_path_map):\n        if not os.path.exists(i[1]):\n            if not os.path.exists(re.sub('training', 'testing', i[1])):\n                shutil.copy(i[0], i[1])","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:34:00.936891Z","iopub.execute_input":"2022-08-21T11:34:00.937203Z","iopub.status.idle":"2022-08-21T11:36:46.617604Z","shell.execute_reply.started":"2022-08-21T11:34:00.937170Z","shell.execute_reply":"2022-08-21T11:36:46.616750Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"  0%|          | 18/21600 [00:00<02:02, 175.62it/s]","output_type":"stream"},{"name":"stdout","text":"moving training files..\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 21600/21600 [02:11<00:00, 164.34it/s]\n  0%|          | 18/5400 [00:00<00:31, 171.18it/s]","output_type":"stream"},{"name":"stdout","text":"moving testing files..\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5400/5400 [00:30<00:00, 176.36it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a ImageDataGenerator Instance which can be used for data augmentation\n\ntrain_gen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=60,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip = True\n#   validation_split=0.2\n)\n\ntrain_generator = train_gen.flow_from_directory(\n    directory=TRAIN_DIR,\n    target_size=(64, 64),\n    batch_size=BATCH_SIZE,\n    class_mode=CLASS_MODE,\n    #subset='training',\n    color_mode='rgb',\n    shuffle=True,\n    seed=69\n)\n# The validation set is optional if we choose to do that\n\"\"\"\nvalid_generator = train_gen.flow_from_directory(\n    directory=TRAIN_DIR,\n    target_size=(64, 64),\n    batch_size=BATCH_SIZE,\n    class_mode=CLASS_MODE,\n    subset='validation',    \n    color_mode='rgb',\n    shuffle=True,\n    seed=69\n)\n\"\"\"\n# test generator for evaluation purposes with no augmentations, just rescaling\ntest_gen = ImageDataGenerator(\n    rescale=1./255,\n)\n\ntest_generator = test_gen.flow_from_directory(\n    directory=TEST_DIR,\n    target_size=(64, 64),\n    batch_size=BATCH_SIZE,\n    class_mode=CLASS_MODE,\n    color_mode='rgb',\n    shuffle=False,\n    seed=69\n)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:36:46.619204Z","iopub.execute_input":"2022-08-21T11:36:46.619395Z","iopub.status.idle":"2022-08-21T11:36:48.201597Z","shell.execute_reply.started":"2022-08-21T11:36:46.619373Z","shell.execute_reply":"2022-08-21T11:36:48.200832Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 21600 images belonging to 10 classes.\nFound 5400 images belonging to 10 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train_generator.class_indices)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:36:48.209815Z","iopub.execute_input":"2022-08-21T11:36:48.210154Z","iopub.status.idle":"2022-08-21T11:36:48.217319Z","shell.execute_reply.started":"2022-08-21T11:36:48.210112Z","shell.execute_reply":"2022-08-21T11:36:48.216553Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"{'AnnualCrop': 0, 'Forest': 1, 'HerbaceousVegetation': 2, 'Highway': 3, 'Industrial': 4, 'Pasture': 5, 'PermanentCrop': 6, 'Residential': 7, 'River': 8, 'SeaLake': 9}\n","output_type":"stream"}]},{"cell_type":"code","source":"np.save('class_indices', train_generator.class_indices)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:36:48.229975Z","iopub.execute_input":"2022-08-21T11:36:48.230252Z","iopub.status.idle":"2022-08-21T11:36:48.235601Z","shell.execute_reply.started":"2022-08-21T11:36:48.230220Z","shell.execute_reply":"2022-08-21T11:36:48.234848Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"The following models are trained for the purpose of **classifying** the dataset:\n1. ResNet50\n3. ResNet152V2\n3. VGG16\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.models import Model\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.optimizers import Adam\n\n\nfrom keras.applications import VGG16, VGG19\nfrom keras.applications import ResNet50, ResNet50V2, ResNet152V2\nfrom keras.applications import InceptionV3, Xception\n\nfrom sklearn.metrics import precision_recall_fscore_support, confusion_matrix, fbeta_score, accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:36:48.237315Z","iopub.execute_input":"2022-08-21T11:36:48.238205Z","iopub.status.idle":"2022-08-21T11:36:48.245341Z","shell.execute_reply.started":"2022-08-21T11:36:48.238162Z","shell.execute_reply":"2022-08-21T11:36:48.244493Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n  # Restrict TensorFlow to only use the first GPU\n  try:\n    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")    \n  except RuntimeError as e:\n    # Visible devices must be set before GPUs have been initialized\n    print(e)\n    \ntf.config.set_soft_device_placement(True)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:36:48.246743Z","iopub.execute_input":"2022-08-21T11:36:48.247245Z","iopub.status.idle":"2022-08-21T11:36:49.996651Z","shell.execute_reply.started":"2022-08-21T11:36:48.247211Z","shell.execute_reply":"2022-08-21T11:36:49.995852Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"1 Physical GPUs, 1 Logical GPU\n","output_type":"stream"}]},{"cell_type":"code","source":"def compile_model(cnn_base, input_shape, n_classes, optimizer, fine_tune=None):\n    \n    if (cnn_base == 'ResNet50') or (cnn_base == 'ResNet152V2'):\n        if cnn_base == 'ResNet50':\n            conv_base = ResNet50(include_top=False,\n                                 weights='imagenet', \n                                 input_shape=input_shape)\n        else:\n            conv_base = ResNet152V2(include_top=False,\n                                 weights='imagenet', \n                                 input_shape=input_shape)\n        top_model = conv_base.output\n        top_model = Flatten()(top_model)\n        top_model = Dense(2048, activation='relu')(top_model)\n        top_model = Dropout(0.2)(top_model)\n       \n    \n    elif (cnn_base == 'VGG16'):\n        if cnn_base == 'VGG16':\n            conv_base = VGG16(include_top=False,\n                              weights='imagenet', \n                              input_shape=input_shape)\n        top_model = conv_base.output\n        top_model = Flatten()(top_model)\n        top_model = Dense(2048, activation='relu')(top_model)\n        top_model = Dropout(0.2)(top_model)\n        top_model = Dense(2048, activation='relu')(top_model)\n        top_model = Dropout(0.2)(top_model)\n    \n    \n    output_layer = Dense(n_classes, activation='softmax')(top_model)\n    \n    model = Model(inputs=conv_base.input, outputs=output_layer)\n        \n    if type(fine_tune) == int:\n        for layer in conv_base.layers[fine_tune:]:\n            layer.trainable = True\n    else:\n        for layer in conv_base.layers:\n            layer.trainable = False\n\n    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n                 metrics=['categorical_accuracy'])\n    \n    return model\n\ndef plot_history(history):\n       \n    acc = history.history['categorical_accuracy']\n    val_acc = history.history['val_categorical_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    \n    plt.figure(figsize=(10, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(acc)\n    plt.plot(val_acc)\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(loss)\n    plt.plot(val_loss)\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    \n    plt.show();\n\ndef display_results(y_true, y_preds, class_labels):\n    \n    results = pd.DataFrame(precision_recall_fscore_support(y_true, y_preds),\n                          columns=class_labels).T\n    results.rename(columns={0: 'Precision',\n                           1: 'Recall',\n                           2: 'F-Score',\n                           3: 'Support'}, inplace=True)\n    \n    conf_mat = pd.DataFrame(confusion_matrix(y_true, y_preds), \n                            columns=class_labels,\n                            index=class_labels)    \n    f2 = fbeta_score(y_true, y_preds, beta=2, average='micro')\n    accuracy = accuracy_score(y_true, y_preds)\n    print(f\"Accuracy: {accuracy}\")\n    print(f\"Global F2 Score: {f2}\")    \n    return results, conf_mat\n\ndef plot_predictions(y_true, y_preds, test_generator, class_indices):\n\n    fig = plt.figure(figsize=(20, 10))\n    for i, idx in enumerate(np.random.choice(test_generator.samples, size=20, replace=False)):\n        ax = fig.add_subplot(4, 5, i + 1, xticks=[], yticks=[])\n        ax.imshow(np.squeeze(test_generator[idx]))\n        pred_idx = np.argmax(y_preds[idx])\n        true_idx = y_true[idx]\n                \n        plt.tight_layout()\n        ax.set_title(\"{}\\n({})\".format(class_indices[pred_idx], class_indices[true_idx]),\n                     color=(\"green\" if pred_idx == true_idx else \"red\"))    ","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:36:49.998056Z","iopub.execute_input":"2022-08-21T11:36:49.998313Z","iopub.status.idle":"2022-08-21T11:36:50.019963Z","shell.execute_reply.started":"2022-08-21T11:36:49.998280Z","shell.execute_reply":"2022-08-21T11:36:50.019159Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"N_STEPS = train_generator.samples//BATCH_SIZE\nN_VAL_STEPS = test_generator.samples//BATCH_SIZE\nN_EPOCHS = 100\n\n# model callbacks\ncheckpoint = ModelCheckpoint(filepath='../working/model.weights.best.hdf5',\n                        monitor='val_categorical_accuracy',\n                        save_best_only=True,\n                        verbose=1)\n\nearly_stop = EarlyStopping(monitor='val_categorical_accuracy',\n                           patience=10,\n                           restore_best_weights=True,\n                           mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5,\n                              patience=3, min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:36:50.034291Z","iopub.execute_input":"2022-08-21T11:36:50.034644Z","iopub.status.idle":"2022-08-21T11:36:50.043550Z","shell.execute_reply.started":"2022-08-21T11:36:50.034612Z","shell.execute_reply":"2022-08-21T11:36:50.042922Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## ResNet50","metadata":{}},{"cell_type":"code","source":"resnet50_model = compile_model('ResNet50', INPUT_SHAPE, NUM_CLASSES, Adam(lr=1e-2), fine_tune=None)\nresnet50_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator.reset()\ntest_generator.reset()\n\nN_STEPS = train_generator.samples//BATCH_SIZE\nN_VAL_STEPS = test_generator.samples//BATCH_SIZE\nN_EPOCHS = 100\n\n# model callbacks\ncheckpoint = ModelCheckpoint(filepath='../working/model.weights.best.hdf5',\n                        monitor='val_categorical_accuracy',\n                        save_best_only=True,\n                        verbose=1)\n\nearly_stop = EarlyStopping(monitor='val_categorical_accuracy',\n                           patience=10,\n                           restore_best_weights=True,\n                           mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5,\n                              patience=3, min_lr=0.00001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pre-training the dense layer\nresnet50_history = resnet50_model.fit_generator(train_generator,\n                             steps_per_epoch=N_STEPS,\n                             epochs=50,\n                             callbacks=[early_stop, checkpoint],\n                             validation_data=test_generator,\n                             validation_steps=N_VAL_STEPS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# re-train whole network end2end \nresnet50_model = compile_model('ResNet50', INPUT_SHAPE, NUM_CLASSES, Adam(lr=1e-4), fine_tune=0)\n\nresnet50_model.load_weights('../working/model.weights.best.hdf5')\n\ntrain_generator.reset()\ntest_generator.reset()\n\nresnet50_history = resnet50_model.fit_generator(train_generator,\n                             steps_per_epoch=N_STEPS,\n                             epochs=N_EPOCHS,\n                             callbacks=[early_stop, checkpoint, reduce_lr],\n                             validation_data=test_generator,\n                             validation_steps=N_VAL_STEPS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(resnet50_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resnet50_model.load_weights('../working/model.weights.best.hdf5')\n\nclass_indices = train_generator.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\n\ntest_generator_new = test_gen.flow_from_directory(\n    directory=TEST_DIR,\n    target_size=(64, 64),\n    batch_size=1,\n    class_mode=None,\n    color_mode='rgb',\n    shuffle=False,\n    seed=69\n)\n\npredictions = resnet50_model.predict_generator(test_generator_new, steps=len(test_generator_new.filenames))\npredicted_classes = np.argmax(np.rint(predictions), axis=1)\ntrue_classes = test_generator_new.classes\n\nprf, conf_mat = display_results(true_classes, predicted_classes, class_indices.values())\nprf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model and the weights\nresnet50_model.save('../working/ResNet50_eurosat.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet152V2 Model","metadata":{}},{"cell_type":"code","source":"resnet152V2_model = compile_model('ResNet152V2', INPUT_SHAPE, NUM_CLASSES, Adam(lr=1e-2), fine_tune=None)\nresnet152V2_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:48:53.224095Z","iopub.execute_input":"2022-08-21T11:48:53.224448Z","iopub.status.idle":"2022-08-21T11:49:02.158229Z","shell.execute_reply.started":"2022-08-21T11:48:53.224407Z","shell.execute_reply":"2022-08-21T11:49:02.157524Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_3 (InputLayer)            (None, 64, 64, 3)    0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 70, 70, 3)    0           input_3[0][0]                    \n__________________________________________________________________________________________________\nconv1_conv (Conv2D)             (None, 32, 32, 64)   9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 34, 34, 64)   0           conv1_conv[0][0]                 \n__________________________________________________________________________________________________\npool1_pool (MaxPooling2D)       (None, 16, 16, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nconv2_block1_preact_bn (BatchNo (None, 16, 16, 64)   256         pool1_pool[0][0]                 \n__________________________________________________________________________________________________\nconv2_block1_preact_relu (Activ (None, 16, 16, 64)   0           conv2_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 16, 16, 64)   4096        conv2_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 16, 16, 64)   0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_pad (ZeroPadding (None, 18, 18, 64)   0           conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 16, 16, 64)   36864       conv2_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv2_block1_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_2_relu (Activation (None, 16, 16, 64)   0           conv2_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_0_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv2_block1_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_out (Add)          (None, 16, 16, 256)  0           conv2_block1_0_conv[0][0]        \n                                                                 conv2_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_preact_bn (BatchNo (None, 16, 16, 256)  1024        conv2_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block2_preact_relu (Activ (None, 16, 16, 256)  0           conv2_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 16, 16, 64)   16384       conv2_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 16, 16, 64)   0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_pad (ZeroPadding (None, 18, 18, 64)   0           conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 16, 16, 64)   36864       conv2_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv2_block2_2_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_2_relu (Activation (None, 16, 16, 64)   0           conv2_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_3_conv (Conv2D)    (None, 16, 16, 256)  16640       conv2_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_out (Add)          (None, 16, 16, 256)  0           conv2_block1_out[0][0]           \n                                                                 conv2_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_preact_bn (BatchNo (None, 16, 16, 256)  1024        conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_preact_relu (Activ (None, 16, 16, 256)  0           conv2_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 16, 16, 64)   16384       conv2_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 16, 16, 64)   256         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 16, 16, 64)   0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_pad (ZeroPadding (None, 18, 18, 64)   0           conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 8, 8, 64)     36864       conv2_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv2_block3_2_bn (BatchNormali (None, 8, 8, 64)     256         conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_2_relu (Activation (None, 8, 8, 64)     0           conv2_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nmax_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 256)    0           conv2_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv2_block3_3_conv (Conv2D)    (None, 8, 8, 256)    16640       conv2_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_out (Add)          (None, 8, 8, 256)    0           max_pooling2d_7[0][0]            \n                                                                 conv2_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_preact_bn (BatchNo (None, 8, 8, 256)    1024        conv2_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block1_preact_relu (Activ (None, 8, 8, 256)    0           conv3_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv3_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 8, 8, 128)    0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block1_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_2_relu (Activation (None, 8, 8, 128)    0           conv3_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_0_conv (Conv2D)    (None, 8, 8, 512)    131584      conv3_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block1_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_out (Add)          (None, 8, 8, 512)    0           conv3_block1_0_conv[0][0]        \n                                                                 conv3_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block2_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 8, 8, 128)    0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block2_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_2_relu (Activation (None, 8, 8, 128)    0           conv3_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_out (Add)          (None, 8, 8, 512)    0           conv3_block1_out[0][0]           \n                                                                 conv3_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block3_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 8, 8, 128)    0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block3_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_2_relu (Activation (None, 8, 8, 128)    0           conv3_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_out (Add)          (None, 8, 8, 512)    0           conv3_block2_out[0][0]           \n                                                                 conv3_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block4_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block4_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block4_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 8, 8, 128)    0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block4_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block4_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_2_relu (Activation (None, 8, 8, 128)    0           conv3_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_out (Add)          (None, 8, 8, 512)    0           conv3_block3_out[0][0]           \n                                                                 conv3_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block5_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block5_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block5_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block5_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_relu (Activation (None, 8, 8, 128)    0           conv3_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block5_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block5_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_2_relu (Activation (None, 8, 8, 128)    0           conv3_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_out (Add)          (None, 8, 8, 512)    0           conv3_block4_out[0][0]           \n                                                                 conv3_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block6_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block6_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block6_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block6_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_relu (Activation (None, 8, 8, 128)    0           conv3_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block6_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block6_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_2_relu (Activation (None, 8, 8, 128)    0           conv3_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_out (Add)          (None, 8, 8, 512)    0           conv3_block5_out[0][0]           \n                                                                 conv3_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block7_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block7_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block7_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block7_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_relu (Activation (None, 8, 8, 128)    0           conv3_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_2_conv (Conv2D)    (None, 8, 8, 128)    147456      conv3_block7_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block7_2_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_2_relu (Activation (None, 8, 8, 128)    0           conv3_block7_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_3_conv (Conv2D)    (None, 8, 8, 512)    66048       conv3_block7_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_out (Add)          (None, 8, 8, 512)    0           conv3_block6_out[0][0]           \n                                                                 conv3_block7_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_preact_bn (BatchNo (None, 8, 8, 512)    2048        conv3_block7_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block8_preact_relu (Activ (None, 8, 8, 512)    0           conv3_block8_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv3_block8_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv3_block8_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv3_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv3_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_relu (Activation (None, 8, 8, 128)    0           conv3_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_2_pad (ZeroPadding (None, 10, 10, 128)  0           conv3_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_2_conv (Conv2D)    (None, 4, 4, 128)    147456      conv3_block8_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv3_block8_2_bn (BatchNormali (None, 4, 4, 128)    512         conv3_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_2_relu (Activation (None, 4, 4, 128)    0           conv3_block8_2_bn[0][0]          \n__________________________________________________________________________________________________\nmax_pooling2d_8 (MaxPooling2D)  (None, 4, 4, 512)    0           conv3_block7_out[0][0]           \n__________________________________________________________________________________________________\nconv3_block8_3_conv (Conv2D)    (None, 4, 4, 512)    66048       conv3_block8_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_out (Add)          (None, 4, 4, 512)    0           max_pooling2d_8[0][0]            \n                                                                 conv3_block8_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_preact_bn (BatchNo (None, 4, 4, 512)    2048        conv3_block8_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block1_preact_relu (Activ (None, 4, 4, 512)    0           conv4_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 4, 4, 256)    131072      conv4_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 4, 4, 256)    0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block1_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_2_relu (Activation (None, 4, 4, 256)    0           conv4_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_0_conv (Conv2D)    (None, 4, 4, 1024)   525312      conv4_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block1_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_out (Add)          (None, 4, 4, 1024)   0           conv4_block1_0_conv[0][0]        \n                                                                 conv4_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block2_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 4, 4, 256)    0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block2_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_2_relu (Activation (None, 4, 4, 256)    0           conv4_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_out (Add)          (None, 4, 4, 1024)   0           conv4_block1_out[0][0]           \n                                                                 conv4_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block3_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 4, 4, 256)    0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block3_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_2_relu (Activation (None, 4, 4, 256)    0           conv4_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_out (Add)          (None, 4, 4, 1024)   0           conv4_block2_out[0][0]           \n                                                                 conv4_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block3_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block4_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block4_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block4_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 4, 4, 256)    0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block4_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block4_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_2_relu (Activation (None, 4, 4, 256)    0           conv4_block4_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block4_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_out (Add)          (None, 4, 4, 1024)   0           conv4_block3_out[0][0]           \n                                                                 conv4_block4_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block4_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block5_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block5_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block5_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 4, 4, 256)    0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block5_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block5_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_2_relu (Activation (None, 4, 4, 256)    0           conv4_block5_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block5_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_out (Add)          (None, 4, 4, 1024)   0           conv4_block4_out[0][0]           \n                                                                 conv4_block5_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block5_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block6_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block6_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block6_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 4, 4, 256)    0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block6_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_out (Add)          (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n                                                                 conv4_block6_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block6_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block7_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block7_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block7_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block7_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block7_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_relu (Activation (None, 4, 4, 256)    0           conv4_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block7_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block7_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_2_relu (Activation (None, 4, 4, 256)    0           conv4_block7_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block7_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_out (Add)          (None, 4, 4, 1024)   0           conv4_block6_out[0][0]           \n                                                                 conv4_block7_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block7_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block8_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block8_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block8_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block8_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block8_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_relu (Activation (None, 4, 4, 256)    0           conv4_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block8_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block8_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_2_relu (Activation (None, 4, 4, 256)    0           conv4_block8_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block8_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_out (Add)          (None, 4, 4, 1024)   0           conv4_block7_out[0][0]           \n                                                                 conv4_block8_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block8_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block9_preact_relu (Activ (None, 4, 4, 1024)   0           conv4_block9_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv4_block9_1_conv (Conv2D)    (None, 4, 4, 256)    262144      conv4_block9_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv4_block9_1_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_relu (Activation (None, 4, 4, 256)    0           conv4_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_2_pad (ZeroPadding (None, 6, 6, 256)    0           conv4_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block9_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv4_block9_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_2_relu (Activation (None, 4, 4, 256)    0           conv4_block9_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block9_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_out (Add)          (None, 4, 4, 1024)   0           conv4_block8_out[0][0]           \n                                                                 conv4_block9_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block9_out[0][0]           \n__________________________________________________________________________________________________\nconv4_block10_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block10_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block10_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block10_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block10_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block10_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block10_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block10_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_out (Add)         (None, 4, 4, 1024)   0           conv4_block9_out[0][0]           \n                                                                 conv4_block10_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block10_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block11_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block11_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block11_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block11_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block11_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block11_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block11_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block11_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block11_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_out (Add)         (None, 4, 4, 1024)   0           conv4_block10_out[0][0]          \n                                                                 conv4_block11_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block11_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block12_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block12_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block12_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block12_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block12_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block12_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block12_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block12_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block12_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_out (Add)         (None, 4, 4, 1024)   0           conv4_block11_out[0][0]          \n                                                                 conv4_block12_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block12_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block13_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block13_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block13_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block13_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block13_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block13_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block13_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block13_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block13_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block13_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block13_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block13_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block13_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_out (Add)         (None, 4, 4, 1024)   0           conv4_block12_out[0][0]          \n                                                                 conv4_block13_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block13_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block14_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block14_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block14_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block14_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block14_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block14_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block14_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block14_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block14_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block14_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block14_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block14_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block14_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_out (Add)         (None, 4, 4, 1024)   0           conv4_block13_out[0][0]          \n                                                                 conv4_block14_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block14_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block15_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block15_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block15_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block15_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block15_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block15_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block15_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block15_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block15_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block15_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block15_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block15_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block15_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_out (Add)         (None, 4, 4, 1024)   0           conv4_block14_out[0][0]          \n                                                                 conv4_block15_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block15_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block16_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block16_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block16_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block16_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block16_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block16_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block16_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block16_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block16_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block16_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block16_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block16_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block16_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_out (Add)         (None, 4, 4, 1024)   0           conv4_block15_out[0][0]          \n                                                                 conv4_block16_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block16_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block17_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block17_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block17_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block17_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block17_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block17_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block17_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block17_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block17_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block17_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block17_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block17_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block17_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_out (Add)         (None, 4, 4, 1024)   0           conv4_block16_out[0][0]          \n                                                                 conv4_block17_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block17_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block18_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block18_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block18_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block18_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block18_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block18_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block18_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block18_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block18_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block18_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block18_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block18_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block18_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_out (Add)         (None, 4, 4, 1024)   0           conv4_block17_out[0][0]          \n                                                                 conv4_block18_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block18_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block19_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block19_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block19_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block19_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block19_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block19_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block19_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block19_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block19_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block19_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block19_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block19_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block19_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_out (Add)         (None, 4, 4, 1024)   0           conv4_block18_out[0][0]          \n                                                                 conv4_block19_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block19_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block20_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block20_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block20_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block20_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block20_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block20_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block20_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block20_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block20_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block20_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block20_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block20_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block20_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_out (Add)         (None, 4, 4, 1024)   0           conv4_block19_out[0][0]          \n                                                                 conv4_block20_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block20_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block21_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block21_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block21_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block21_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block21_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block21_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block21_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block21_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block21_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block21_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block21_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block21_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block21_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_out (Add)         (None, 4, 4, 1024)   0           conv4_block20_out[0][0]          \n                                                                 conv4_block21_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block21_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block22_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block22_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block22_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block22_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block22_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block22_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block22_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block22_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block22_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block22_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block22_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block22_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block22_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_out (Add)         (None, 4, 4, 1024)   0           conv4_block21_out[0][0]          \n                                                                 conv4_block22_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block22_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block23_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block23_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block23_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block23_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block23_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block23_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block23_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block23_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block23_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block23_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block23_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block23_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block23_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_out (Add)         (None, 4, 4, 1024)   0           conv4_block22_out[0][0]          \n                                                                 conv4_block23_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block23_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block24_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block24_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block24_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block24_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block24_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block24_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block24_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block24_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block24_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block24_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block24_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block24_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block24_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_out (Add)         (None, 4, 4, 1024)   0           conv4_block23_out[0][0]          \n                                                                 conv4_block24_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block24_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block25_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block25_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block25_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block25_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block25_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block25_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block25_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block25_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block25_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block25_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block25_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block25_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block25_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block25_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block25_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block25_out (Add)         (None, 4, 4, 1024)   0           conv4_block24_out[0][0]          \n                                                                 conv4_block25_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block25_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block26_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block26_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block26_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block26_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block26_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block26_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block26_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block26_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block26_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block26_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block26_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block26_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block26_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block26_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block26_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block26_out (Add)         (None, 4, 4, 1024)   0           conv4_block25_out[0][0]          \n                                                                 conv4_block26_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block26_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block27_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block27_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block27_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block27_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block27_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block27_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block27_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block27_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block27_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block27_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block27_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block27_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block27_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block27_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block27_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block27_out (Add)         (None, 4, 4, 1024)   0           conv4_block26_out[0][0]          \n                                                                 conv4_block27_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block27_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block28_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block28_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block28_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block28_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block28_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block28_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block28_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block28_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block28_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block28_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block28_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block28_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block28_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block28_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block28_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block28_out (Add)         (None, 4, 4, 1024)   0           conv4_block27_out[0][0]          \n                                                                 conv4_block28_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block28_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block29_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block29_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block29_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block29_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block29_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block29_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block29_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block29_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block29_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block29_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block29_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block29_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block29_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block29_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block29_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block29_out (Add)         (None, 4, 4, 1024)   0           conv4_block28_out[0][0]          \n                                                                 conv4_block29_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block29_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block30_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block30_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block30_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block30_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block30_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block30_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block30_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block30_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block30_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block30_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block30_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block30_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block30_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block30_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block30_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block30_out (Add)         (None, 4, 4, 1024)   0           conv4_block29_out[0][0]          \n                                                                 conv4_block30_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block30_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block31_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block31_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block31_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block31_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block31_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block31_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block31_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block31_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block31_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block31_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block31_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block31_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block31_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block31_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block31_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block31_out (Add)         (None, 4, 4, 1024)   0           conv4_block30_out[0][0]          \n                                                                 conv4_block31_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block31_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block32_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block32_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block32_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block32_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block32_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block32_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block32_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block32_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block32_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block32_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block32_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block32_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block32_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block32_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block32_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block32_out (Add)         (None, 4, 4, 1024)   0           conv4_block31_out[0][0]          \n                                                                 conv4_block32_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block32_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block33_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block33_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block33_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block33_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block33_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block33_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block33_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block33_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block33_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block33_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block33_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block33_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block33_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block33_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block33_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block33_out (Add)         (None, 4, 4, 1024)   0           conv4_block32_out[0][0]          \n                                                                 conv4_block33_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block33_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block34_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block34_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block34_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block34_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block34_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block34_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block34_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block34_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block34_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block34_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block34_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block34_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block34_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block34_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block34_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block34_out (Add)         (None, 4, 4, 1024)   0           conv4_block33_out[0][0]          \n                                                                 conv4_block34_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block34_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block35_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block35_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block35_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block35_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block35_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block35_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block35_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block35_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block35_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_2_conv (Conv2D)   (None, 4, 4, 256)    589824      conv4_block35_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block35_2_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block35_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_2_relu (Activatio (None, 4, 4, 256)    0           conv4_block35_2_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block35_3_conv (Conv2D)   (None, 4, 4, 1024)   263168      conv4_block35_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block35_out (Add)         (None, 4, 4, 1024)   0           conv4_block34_out[0][0]          \n                                                                 conv4_block35_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_preact_bn (BatchN (None, 4, 4, 1024)   4096        conv4_block35_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block36_preact_relu (Acti (None, 4, 4, 1024)   0           conv4_block36_preact_bn[0][0]    \n__________________________________________________________________________________________________\nconv4_block36_1_conv (Conv2D)   (None, 4, 4, 256)    262144      conv4_block36_preact_relu[0][0]  \n__________________________________________________________________________________________________\nconv4_block36_1_bn (BatchNormal (None, 4, 4, 256)    1024        conv4_block36_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_1_relu (Activatio (None, 4, 4, 256)    0           conv4_block36_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block36_2_pad (ZeroPaddin (None, 6, 6, 256)    0           conv4_block36_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_2_conv (Conv2D)   (None, 2, 2, 256)    589824      conv4_block36_2_pad[0][0]        \n__________________________________________________________________________________________________\nconv4_block36_2_bn (BatchNormal (None, 2, 2, 256)    1024        conv4_block36_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_2_relu (Activatio (None, 2, 2, 256)    0           conv4_block36_2_bn[0][0]         \n__________________________________________________________________________________________________\nmax_pooling2d_9 (MaxPooling2D)  (None, 2, 2, 1024)   0           conv4_block35_out[0][0]          \n__________________________________________________________________________________________________\nconv4_block36_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      conv4_block36_2_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block36_out (Add)         (None, 2, 2, 1024)   0           max_pooling2d_9[0][0]            \n                                                                 conv4_block36_3_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block1_preact_bn (BatchNo (None, 2, 2, 1024)   4096        conv4_block36_out[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_preact_relu (Activ (None, 2, 2, 1024)   0           conv5_block1_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, 2, 2, 512)    524288      conv5_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, 2, 2, 512)    0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_pad (ZeroPadding (None, 4, 4, 512)    0           conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, 2, 2, 512)    2359296     conv5_block1_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block1_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_2_relu (Activation (None, 2, 2, 512)    0           conv5_block1_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_0_conv (Conv2D)    (None, 2, 2, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block1_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block1_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_out (Add)          (None, 2, 2, 2048)   0           conv5_block1_0_conv[0][0]        \n                                                                 conv5_block1_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_preact_bn (BatchNo (None, 2, 2, 2048)   8192        conv5_block1_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block2_preact_relu (Activ (None, 2, 2, 2048)   0           conv5_block2_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, 2, 2, 512)    1048576     conv5_block2_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, 2, 2, 512)    0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_pad (ZeroPadding (None, 4, 4, 512)    0           conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, 2, 2, 512)    2359296     conv5_block2_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block2_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_2_relu (Activation (None, 2, 2, 512)    0           conv5_block2_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block2_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_out (Add)          (None, 2, 2, 2048)   0           conv5_block1_out[0][0]           \n                                                                 conv5_block2_3_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_preact_bn (BatchNo (None, 2, 2, 2048)   8192        conv5_block2_out[0][0]           \n__________________________________________________________________________________________________\nconv5_block3_preact_relu (Activ (None, 2, 2, 2048)   0           conv5_block3_preact_bn[0][0]     \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, 2, 2, 512)    1048576     conv5_block3_preact_relu[0][0]   \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, 2, 2, 512)    0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_pad (ZeroPadding (None, 4, 4, 512)    0           conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, 2, 2, 512)    2359296     conv5_block3_2_pad[0][0]         \n__________________________________________________________________________________________________\nconv5_block3_2_bn (BatchNormali (None, 2, 2, 512)    2048        conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_2_relu (Activation (None, 2, 2, 512)    0           conv5_block3_2_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_3_conv (Conv2D)    (None, 2, 2, 2048)   1050624     conv5_block3_2_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_out (Add)          (None, 2, 2, 2048)   0           conv5_block2_out[0][0]           \n                                                                 conv5_block3_3_conv[0][0]        \n__________________________________________________________________________________________________\npost_bn (BatchNormalization)    (None, 2, 2, 2048)   8192        conv5_block3_out[0][0]           \n__________________________________________________________________________________________________\npost_relu (Activation)          (None, 2, 2, 2048)   0           post_bn[0][0]                    \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 8192)         0           post_relu[0][0]                  \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 2048)         16779264    flatten_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 2048)         0           dense_5[0][0]                    \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 10)           20490       dropout_3[0][0]                  \n==================================================================================================\nTotal params: 75,131,402\nTrainable params: 16,799,754\nNon-trainable params: 58,331,648\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_generator.reset()\ntest_generator.reset()\n\nN_STEPS = train_generator.samples//BATCH_SIZE\nN_VAL_STEPS = test_generator.samples//BATCH_SIZE\nN_EPOCHS = 100\n\n# model callbacks\ncheckpoint = ModelCheckpoint(filepath='../working/model.weights.best.hdf5',\n                        monitor='val_categorical_accuracy',\n                        save_best_only=True,\n                        verbose=1)\n\nearly_stop = EarlyStopping(monitor='val_categorical_accuracy',\n                           patience=10,\n                           restore_best_weights=True,\n                           mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5,\n                              patience=3, min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:49:12.673830Z","iopub.execute_input":"2022-08-21T11:49:12.674103Z","iopub.status.idle":"2022-08-21T11:49:12.680179Z","shell.execute_reply.started":"2022-08-21T11:49:12.674075Z","shell.execute_reply":"2022-08-21T11:49:12.679420Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# First Pretraining the dense layer\nresnet152V2_history = resnet152V2_model.fit_generator(train_generator,\n                             steps_per_epoch=N_STEPS,\n                             epochs=50,\n                             callbacks=[early_stop, checkpoint],\n                             validation_data=test_generator,\n                             validation_steps=N_VAL_STEPS)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:49:15.623973Z","iopub.execute_input":"2022-08-21T11:49:15.624246Z","iopub.status.idle":"2022-08-21T12:04:53.934243Z","shell.execute_reply.started":"2022-08-21T11:49:15.624216Z","shell.execute_reply":"2022-08-21T12:04:53.933285Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Epoch 1/50\n337/337 [==============================] - 58s 172ms/step - loss: 2.2394 - categorical_accuracy: 0.5645 - val_loss: 1.3424 - val_categorical_accuracy: 0.3903\n\nEpoch 00001: val_categorical_accuracy improved from -inf to 0.39025, saving model to ../working/model.weights.best.hdf5\nEpoch 2/50\n337/337 [==============================] - 46s 135ms/step - loss: 1.5507 - categorical_accuracy: 0.5916 - val_loss: 1.2871 - val_categorical_accuracy: 0.3819\n\nEpoch 00002: val_categorical_accuracy did not improve from 0.39025\nEpoch 3/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.4751 - categorical_accuracy: 0.5950 - val_loss: 1.2239 - val_categorical_accuracy: 0.3757\n\nEpoch 00003: val_categorical_accuracy did not improve from 0.39025\nEpoch 4/50\n337/337 [==============================] - 46s 136ms/step - loss: 1.5095 - categorical_accuracy: 0.5997 - val_loss: 2.6393 - val_categorical_accuracy: 0.3750\n\nEpoch 00004: val_categorical_accuracy did not improve from 0.39025\nEpoch 5/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.4668 - categorical_accuracy: 0.6027 - val_loss: 0.8514 - val_categorical_accuracy: 0.3936\n\nEpoch 00005: val_categorical_accuracy improved from 0.39025 to 0.39355, saving model to ../working/model.weights.best.hdf5\nEpoch 6/50\n337/337 [==============================] - 46s 137ms/step - loss: 1.4260 - categorical_accuracy: 0.6115 - val_loss: 1.6741 - val_categorical_accuracy: 0.4052\n\nEpoch 00006: val_categorical_accuracy improved from 0.39355 to 0.40517, saving model to ../working/model.weights.best.hdf5\nEpoch 7/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.4506 - categorical_accuracy: 0.6056 - val_loss: 1.0078 - val_categorical_accuracy: 0.4097\n\nEpoch 00007: val_categorical_accuracy improved from 0.40517 to 0.40967, saving model to ../working/model.weights.best.hdf5\nEpoch 8/50\n337/337 [==============================] - 45s 135ms/step - loss: 1.3944 - categorical_accuracy: 0.6165 - val_loss: 1.0817 - val_categorical_accuracy: 0.4138\n\nEpoch 00008: val_categorical_accuracy improved from 0.40967 to 0.41379, saving model to ../working/model.weights.best.hdf5\nEpoch 9/50\n337/337 [==============================] - 46s 135ms/step - loss: 1.3843 - categorical_accuracy: 0.6203 - val_loss: 2.2949 - val_categorical_accuracy: 0.3846\n\nEpoch 00009: val_categorical_accuracy did not improve from 0.41379\nEpoch 10/50\n337/337 [==============================] - 45s 135ms/step - loss: 1.4035 - categorical_accuracy: 0.6056 - val_loss: 2.6287 - val_categorical_accuracy: 0.4224\n\nEpoch 00010: val_categorical_accuracy improved from 0.41379 to 0.42241, saving model to ../working/model.weights.best.hdf5\nEpoch 11/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.3867 - categorical_accuracy: 0.6154 - val_loss: 2.2989 - val_categorical_accuracy: 0.4121\n\nEpoch 00011: val_categorical_accuracy did not improve from 0.42241\nEpoch 12/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.3807 - categorical_accuracy: 0.6074 - val_loss: 3.1632 - val_categorical_accuracy: 0.4112\n\nEpoch 00012: val_categorical_accuracy did not improve from 0.42241\nEpoch 13/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.3822 - categorical_accuracy: 0.6189 - val_loss: 2.0412 - val_categorical_accuracy: 0.3791\n\nEpoch 00013: val_categorical_accuracy did not improve from 0.42241\nEpoch 14/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.3696 - categorical_accuracy: 0.6131 - val_loss: 2.3740 - val_categorical_accuracy: 0.3834\n\nEpoch 00014: val_categorical_accuracy did not improve from 0.42241\nEpoch 15/50\n337/337 [==============================] - 45s 133ms/step - loss: 1.3634 - categorical_accuracy: 0.6140 - val_loss: 2.1592 - val_categorical_accuracy: 0.3857\n\nEpoch 00015: val_categorical_accuracy did not improve from 0.42241\nEpoch 16/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.3265 - categorical_accuracy: 0.6243 - val_loss: 4.2202 - val_categorical_accuracy: 0.3879\n\nEpoch 00016: val_categorical_accuracy did not improve from 0.42241\nEpoch 17/50\n337/337 [==============================] - 45s 133ms/step - loss: 1.4054 - categorical_accuracy: 0.6100 - val_loss: 3.5199 - val_categorical_accuracy: 0.3906\n\nEpoch 00017: val_categorical_accuracy did not improve from 0.42241\nEpoch 18/50\n337/337 [==============================] - 45s 134ms/step - loss: 1.3447 - categorical_accuracy: 0.6223 - val_loss: 2.9675 - val_categorical_accuracy: 0.4132\n\nEpoch 00018: val_categorical_accuracy did not improve from 0.42241\nEpoch 19/50\n337/337 [==============================] - 45s 133ms/step - loss: 1.3594 - categorical_accuracy: 0.6150 - val_loss: 3.4210 - val_categorical_accuracy: 0.3943\n\nEpoch 00019: val_categorical_accuracy did not improve from 0.42241\nEpoch 20/50\n337/337 [==============================] - 45s 133ms/step - loss: 1.3626 - categorical_accuracy: 0.6058 - val_loss: 3.4940 - val_categorical_accuracy: 0.3939\n\nEpoch 00020: val_categorical_accuracy did not improve from 0.42241\n","output_type":"stream"}]},{"cell_type":"code","source":"# re-train whole network end2end \nresnet152V2_model = compile_model('ResNet152V2', INPUT_SHAPE, NUM_CLASSES, Adam(lr=1e-4), fine_tune=0)\n\nresnet152V2_model.load_weights('../working/model.weights.best.hdf5')\n\ntrain_generator.reset()\ntest_generator.reset()\n\nresnet152V2_history = resnet152V2_model.fit_generator(train_generator,\n                             steps_per_epoch=N_STEPS,\n                             epochs=N_EPOCHS,\n                             callbacks=[early_stop, checkpoint, reduce_lr],\n                             validation_data=test_generator,\n                             validation_steps=N_VAL_STEPS)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T12:04:53.936000Z","iopub.execute_input":"2022-08-21T12:04:53.936315Z","iopub.status.idle":"2022-08-21T13:04:42.745683Z","shell.execute_reply.started":"2022-08-21T12:04:53.936279Z","shell.execute_reply":"2022-08-21T13:04:42.744819Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1/100\n337/337 [==============================] - 217s 644ms/step - loss: 1.0755 - categorical_accuracy: 0.7059 - val_loss: 8.7625 - val_categorical_accuracy: 0.7312\n\nEpoch 00001: val_categorical_accuracy improved from 0.42241 to 0.73121, saving model to ../working/model.weights.best.hdf5\nEpoch 2/100\n337/337 [==============================] - 121s 359ms/step - loss: 0.6537 - categorical_accuracy: 0.8177 - val_loss: 0.0449 - val_categorical_accuracy: 0.8623\n\nEpoch 00002: val_categorical_accuracy improved from 0.73121 to 0.86226, saving model to ../working/model.weights.best.hdf5\nEpoch 3/100\n337/337 [==============================] - 121s 358ms/step - loss: 0.4763 - categorical_accuracy: 0.8682 - val_loss: 0.1574 - val_categorical_accuracy: 0.8587\n\nEpoch 00003: val_categorical_accuracy did not improve from 0.86226\nEpoch 4/100\n337/337 [==============================] - 120s 356ms/step - loss: 0.3765 - categorical_accuracy: 0.8953 - val_loss: 0.1801 - val_categorical_accuracy: 0.9063\n\nEpoch 00004: val_categorical_accuracy improved from 0.86226 to 0.90630, saving model to ../working/model.weights.best.hdf5\nEpoch 5/100\n337/337 [==============================] - 121s 358ms/step - loss: 0.3291 - categorical_accuracy: 0.9089 - val_loss: 0.0852 - val_categorical_accuracy: 0.9307\n\nEpoch 00005: val_categorical_accuracy improved from 0.90630 to 0.93066, saving model to ../working/model.weights.best.hdf5\nEpoch 6/100\n337/337 [==============================] - 121s 359ms/step - loss: 0.2758 - categorical_accuracy: 0.9195 - val_loss: 0.1706 - val_categorical_accuracy: 0.9352\n\nEpoch 00006: val_categorical_accuracy improved from 0.93066 to 0.93516, saving model to ../working/model.weights.best.hdf5\nEpoch 7/100\n337/337 [==============================] - 122s 362ms/step - loss: 0.2526 - categorical_accuracy: 0.9259 - val_loss: 0.5854 - val_categorical_accuracy: 0.8197\n\nEpoch 00007: val_categorical_accuracy did not improve from 0.93516\nEpoch 8/100\n337/337 [==============================] - 122s 362ms/step - loss: 0.2384 - categorical_accuracy: 0.9311 - val_loss: 0.2540 - val_categorical_accuracy: 0.9376\n\nEpoch 00008: val_categorical_accuracy improved from 0.93516 to 0.93759, saving model to ../working/model.weights.best.hdf5\nEpoch 9/100\n337/337 [==============================] - 121s 359ms/step - loss: 0.2240 - categorical_accuracy: 0.9360 - val_loss: 0.1112 - val_categorical_accuracy: 0.9160\n\nEpoch 00009: val_categorical_accuracy did not improve from 0.93759\nEpoch 10/100\n337/337 [==============================] - 120s 357ms/step - loss: 0.2264 - categorical_accuracy: 0.9350 - val_loss: 0.2953 - val_categorical_accuracy: 0.9029\n\nEpoch 00010: val_categorical_accuracy did not improve from 0.93759\nEpoch 11/100\n337/337 [==============================] - 121s 358ms/step - loss: 0.2032 - categorical_accuracy: 0.9408 - val_loss: 0.0557 - val_categorical_accuracy: 0.9472\n\nEpoch 00011: val_categorical_accuracy improved from 0.93759 to 0.94715, saving model to ../working/model.weights.best.hdf5\nEpoch 12/100\n337/337 [==============================] - 121s 360ms/step - loss: 0.1934 - categorical_accuracy: 0.9421 - val_loss: 0.4770 - val_categorical_accuracy: 0.7835\n\nEpoch 00012: val_categorical_accuracy did not improve from 0.94715\nEpoch 13/100\n337/337 [==============================] - 122s 361ms/step - loss: 0.1791 - categorical_accuracy: 0.9457 - val_loss: 0.2166 - val_categorical_accuracy: 0.8756\n\nEpoch 00013: val_categorical_accuracy did not improve from 0.94715\nEpoch 14/100\n337/337 [==============================] - 120s 358ms/step - loss: 0.1856 - categorical_accuracy: 0.9428 - val_loss: 0.2284 - val_categorical_accuracy: 0.9065\n\nEpoch 00014: val_categorical_accuracy did not improve from 0.94715\nEpoch 15/100\n337/337 [==============================] - 121s 358ms/step - loss: 0.1450 - categorical_accuracy: 0.9551 - val_loss: 0.0894 - val_categorical_accuracy: 0.9590\n\nEpoch 00015: val_categorical_accuracy improved from 0.94715 to 0.95896, saving model to ../working/model.weights.best.hdf5\nEpoch 16/100\n337/337 [==============================] - 121s 360ms/step - loss: 0.1265 - categorical_accuracy: 0.9610 - val_loss: 0.1185 - val_categorical_accuracy: 0.9511\n\nEpoch 00016: val_categorical_accuracy did not improve from 0.95896\nEpoch 17/100\n337/337 [==============================] - 121s 359ms/step - loss: 0.1198 - categorical_accuracy: 0.9625 - val_loss: 0.0016 - val_categorical_accuracy: 0.9477\n\nEpoch 00017: val_categorical_accuracy did not improve from 0.95896\nEpoch 18/100\n337/337 [==============================] - 121s 359ms/step - loss: 0.1262 - categorical_accuracy: 0.9605 - val_loss: 5.9350e-04 - val_categorical_accuracy: 0.9616\n\nEpoch 00018: val_categorical_accuracy improved from 0.95896 to 0.96158, saving model to ../working/model.weights.best.hdf5\nEpoch 19/100\n337/337 [==============================] - 121s 359ms/step - loss: 0.1169 - categorical_accuracy: 0.9632 - val_loss: 6.9702e-04 - val_categorical_accuracy: 0.8849\n\nEpoch 00019: val_categorical_accuracy did not improve from 0.96158\nEpoch 20/100\n337/337 [==============================] - 121s 359ms/step - loss: 0.1185 - categorical_accuracy: 0.9628 - val_loss: 0.0017 - val_categorical_accuracy: 0.9451\n\nEpoch 00020: val_categorical_accuracy did not improve from 0.96158\nEpoch 21/100\n337/337 [==============================] - 121s 358ms/step - loss: 0.1178 - categorical_accuracy: 0.9639 - val_loss: 7.2775e-05 - val_categorical_accuracy: 0.9550\n\nEpoch 00021: val_categorical_accuracy did not improve from 0.96158\nEpoch 22/100\n337/337 [==============================] - 121s 359ms/step - loss: 0.0983 - categorical_accuracy: 0.9689 - val_loss: 8.8300e-05 - val_categorical_accuracy: 0.9516\n\nEpoch 00022: val_categorical_accuracy did not improve from 0.96158\nEpoch 23/100\n337/337 [==============================] - 120s 358ms/step - loss: 0.0901 - categorical_accuracy: 0.9712 - val_loss: 4.3989e-04 - val_categorical_accuracy: 0.9610\n\nEpoch 00023: val_categorical_accuracy did not improve from 0.96158\nEpoch 24/100\n337/337 [==============================] - 120s 358ms/step - loss: 0.0821 - categorical_accuracy: 0.9741 - val_loss: 2.9705e-05 - val_categorical_accuracy: 0.9425\n\nEpoch 00024: val_categorical_accuracy did not improve from 0.96158\nEpoch 25/100\n337/337 [==============================] - 121s 360ms/step - loss: 0.0738 - categorical_accuracy: 0.9761 - val_loss: 5.1727e-05 - val_categorical_accuracy: 0.9599\n\nEpoch 00025: val_categorical_accuracy did not improve from 0.96158\nEpoch 26/100\n337/337 [==============================] - 120s 357ms/step - loss: 0.0706 - categorical_accuracy: 0.9775 - val_loss: 1.7601e-06 - val_categorical_accuracy: 0.9565\n\nEpoch 00026: val_categorical_accuracy did not improve from 0.96158\nEpoch 27/100\n337/337 [==============================] - 123s 365ms/step - loss: 0.0650 - categorical_accuracy: 0.9781 - val_loss: 0.0684 - val_categorical_accuracy: 0.9537\n\nEpoch 00027: val_categorical_accuracy did not improve from 0.96158\nEpoch 28/100\n337/337 [==============================] - 121s 360ms/step - loss: 0.0669 - categorical_accuracy: 0.9784 - val_loss: 0.2760 - val_categorical_accuracy: 0.9503\n\nEpoch 00028: val_categorical_accuracy did not improve from 0.96158\n","output_type":"stream"}]},{"cell_type":"code","source":"plot_history(resnet152V2_history)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:06:07.908057Z","iopub.execute_input":"2022-08-21T13:06:07.908350Z","iopub.status.idle":"2022-08-21T13:06:08.196975Z","shell.execute_reply.started":"2022-08-21T13:06:07.908320Z","shell.execute_reply":"2022-08-21T13:06:08.196242Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x360 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAmcAAAE9CAYAAABOT8UdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeXicZdX48e9JZpLJnjRJ23QvbaGLdIFSQRbZd1lEEBRfRAUVRcANUH/qyyuvvi64gSgILohiRRHUsm9FKUtXaFO60zZNmmZfJ+vcvz/umWSSTpJJMs/M5Mn5XFeuJDPPzNwpdHpy7vucI8YYlFJKKaVUckhJ9AKUUkoppVQvDc6UUkoppZKIBmdKKaWUUklEgzOllFJKqSSiwZlSSimlVBLR4EwppZRSKol4Er2AWCkqKjKzZs1K9DKUUnG0bt26amNMcaLXEQv6HqbU+DLY+5drgrNZs2axdu3aRC9DKRVHIrI30WuIFX0PU2p8Gez9S7c1lVJKKaWSiAZnSimllFJJRIMzpZRSSqkk4pozZ5F0dnZSVlZGW1tbopfiOJ/Px7Rp0/B6vYleilIqRsbLe5i+fynVl6uDs7KyMnJycpg1axYikujlOMYYQ01NDWVlZcyePTvRy1FKxch4eA/T9y+lDufqbc22tjYKCwtd+6YWIiIUFha6/rdrpcab8fAepu9fSh3O1cEZ4Oo3tXDj5edUarwZD3+3x8PPqNRwuD44S7T6+np+8YtfDPtx559/PvX19Q6sSCmloqPvX0olhgZnDhvoza27u3vQx61atYr8/HynlqWUUkPS9y+lEsPVBQHJ4LbbbmPXrl0sXboUr9dLdnY2JSUlbNy4kdLSUi655BL2799PW1sbN910E9dffz3Q2y28ubmZ8847j5NOOolXX32VqVOn8vjjj5ORkZHgn0yp6BhjaOnoptHfSWtHF+1dAfvRGaCjO0B7Z3fws739lCOLmFaQmehlJ69OP3Q0Q0YhpDj7+7W+fymVGBqcOex73/semzdvZuPGjbz00ktccMEFbN68uacq6cEHH2TChAn4/X6OO+44LrvsMgoLC/s8x44dO/jTn/7E/fffzxVXXMFf//pXrr766kT8OEr1aOvsZl9tK7urWni3poW9Na00+Dto9HfR2NZJg7+TRn8njW1ddAdM1M/7q48dq8HZYDqaoaEMfPk4vfmh719KJca4Cc7++x9bKC1vjOlzLpySy7c+sGhYj1mxYkWfcvGf/exnPPbYYwDs37+fHTt2HPbmNnv2bJYuXQrAsccey7vvvju6hSs1DI1tnWwua2B7ZRN7qlvYXd3CnuoWDtT7MWEx14SsNAoyveRmeJmQlcaswizyMrzkZnjsZ5+XzHQP6Z4U0j0ppHlSSPekHvZ9fqb2uoqk5z0s0Ald7eB9A2R0wdlw38P0/Uup+Bg3wVmyyMrK6vn6pZde4rnnnmPNmjVkZmZy6qmnRiwnT09P7/k6NTUVv98fl7Wq8aets5st5Q1s2t/AW2X1vFXWwO7qlp77s9M9zC7K4pgZBVx2zDSOKM5idlEWs4qyyPVpUBUfiats1PcvpeJj3ARnw81wxUpOTg5NTU0R72toaKCgoIDMzEzeeecdXnvttTivTo13Le1drN5exeodVWzcb7NjoS3ISbnpLJ6WzwePmcriafnML8mhODtd2x4kSM97mL8B6nZD0ZGQljX4g0ZJ37+USoxxE5wlSmFhISeeeCLvec97yMjIYNKkST33nXvuufzyl79k8eLFHHXUURx//PEJXKkaL6qa2nl+ayXPlFby753VdHQFyPF5WDo9nzPmz2HxtDyWTM9nUq4v0UtVkYSCYxP9Ob6R0vcvpRJDTBz+gsfD8uXLzdq1a/vctnXrVhYsWJCgFcXfePt5VfR2VzXzbKkNyNbvq8MYmFaQwdkLJ3PWwkkcN6sAT+rY66wjIuuMMcsTvY5YiPo9rL0ZanbAhDngy43jCp2l719qvBns/UszZ0q5jDGGsjo/b75byxt7anl9Ty17gufG3jM1l5vPOJKzF01i/uQc3aIci0JFACaQ2HUopRyjwZlSY5wxhl1Vzbyxp4439tTwxp5ayhvswexcn4cVsydwzQkzOWvRZKbma3+pMa8noHbHrodS6nAanCk1RjW1dXLf6t388fV91LR0AFCck86K2RP49KwJrJg9gaMm5ZCSotkxV9HMmVKup8GZUmNMe1c3f3htH3e/sIO61k7OXjiJMxZMZMXsQmYVZupWpdtpcKaU62lwptQY0R0w/H3DAe56djsH6v2cPK+Ir54zn6On5SV6aSqe4litqZRKDA3OlEpyxhhe3HaI/3tyG9sqmzh6ah7/d9liTppXlOilqUTQzJlSrqfBWZLJzs6mubk50ctQCdbVHeBgYxs7DzXzixd38ca7tcwszOTnVy3jgqNL9BzZuBbKnCVfcKbvX0rFhgZnSkXQHTCkjjAAqmvpYPWOKv6zs5qubkNmeipZ6R6y0zxkpnvIDn6flebBYCivb6O83s+Ber/9XOfnYGMboVnhRdnp/M/Fi7hyxQy8Y7AXmYoxEZs9021NpVxLgzOH3XrrrcycOZMbbrgBgG9/+9uICKtXr6auro7Ozk6+853vcPHFFyd4peNTU1snOw81s+NQMzuDHzsONVFW52daQQbLphewdHo+y2bks3BKLumeVPvA7k7oaIaMAowxlFY08uI7h3hxWxUb9tURMFCQ6SUr3UNLexctHd10dA2c6fCkCCX5PqbkZXD8nEKm5mcwNT+DKfkZLJ9VQGaa/lVV4SQumTN9/1IqMfQd32FXXnklN998c8+b28qVK3nqqae45ZZbyM3Npbq6muOPP56LLrpIq+zioDtg+NMb+3h6y0F2VDZzsLF3UHOaJ4UjirJYOr2ADyyewp7qFt58t5YnNpXb+1NTWDgll2XT87i+/BvkNu/mjll/4KXth6hsbAdgybQ8bjx9HqfPn8jRU/P6bD92dAVo7eiiub2L1o5umtu7MAam5mdQnJM+4kzdoAIB+M+PYepyOOL9sX9+lRiSEpfgTN+/lEqM8ROcPXkbHHw7ts85+Wg473uDXrJs2TIOHTpEeXk5VVVVFBQUUFJSwi233MLq1atJSUnhwIEDVFZWMnny5NiuT/WxtaKR2//2Nhv313PUpBzeN6eQuZOymTcxh3kTs5k+ITNigFTR4Gfjvno27q9nw7562tf+npKUFwF4bvNejp83ldPmT+T9RxZTnJM+4OuneVJI86SRn5nm2M/YR6AbnrgRNj4MuVPhCxvAM/D6BrX+99BYAUd/CArnxHadKjrh72GdLSCp4Bnl/NMh3sP0/UupxBg/wVkCfehDH+LRRx/l4MGDXHnllTz88MNUVVWxbt06vF4vs2bNoq2tbegnUkPz18E/boYV18GskwBo6+zmp8/v4P7Vu8nL8PKTDy/l4qVTov5NvyQvg5KjMzjv6BKo34f5xR/pDmSS2tXKazcchXfikU7+RCMT6IbHPw+b/ggLLoKtT9gAa8V1w3+u6h32z9R0w0v/a7Nwiz8M7/kgZGnFaGII8ZoQoO9fSsXf+AnOhshwOenKK6/kuuuuo7q6mpdffpmVK1cyceJEvF4vL774Inv37k3Y2lxnz2oo/Tu880+48Me8knMeX39sM/tqW7li+TRuP28BBVkjzFwFAvD45xAMqRfeBX//DN7G/ZBswVmgG/5+A7z1CJz6NXj/V+E358MrP4JlV4N3mCOcnr/DPubaVbD7ZXhrJTz5FXjqNph7hg3Ujjof0jKd+XnGKBG5BfgUNop6G7jWGDPyKCb8PaxqG6SkQuHcUa5yaPr+pVT8jZ/gLIEWLVpEU1MTU6dOpaSkhI9+9KN84AMfYPny5SxdupT58+cneonuUbkFJIWO6e8j7Ykb2dZ1Hml51/Gn647nhDmFo3vutQ/Y4O8DP+3JytGwf/RrjqXwwOy0b8D7v2JvP+1r8LsLYd1v4fjPRv98+9+0WbdTvwYlS+zHiV+wf85vrYS3H4W/fhK8WbDgQph/Icw5DdJzHPnxxgoRmQp8AVhojPGLyErgSuC3sXmB+Jw5A33/UioRNDiLk7ff7j3vVlRUxJo1ayJepz2CRsdUbqYpaxan7buBm7oz+JTnSa6d3EXq1AdH98Q1u+DZb8LcM+GYa2wQJKlQvy82Cx9I/T7w5dmPoQS64bHPwNsr4fRvwClf6b1v9skw62R45S67/miyXMbYnzmrGE74XN/7Ji2Cs/4bzvgW7HsV3vozlD5uP6em2eD1yHPtR8HM4f3M7uEBMkSkE8gEymP2zJICga6YPd1Q9P1LqfjSpknKVZr3bmJ1w0RmT8zjhM8/ABfcReruF+CBs6Hu3ZE9aaAb/v5ZSPXCRT+3faZSPfaQfb2DmbNdL8DPj4UfzIOV18A7q6CrI/K13V3w2KeDgdn/6xuYhZz2NWg5ZDOA0djxjA283n8rpGdHviYlxQZiF/0cvrILPv4vWHG9/XN58qvw08Vwz/Hw3Ldh32v2z3IcMMYcAH4I7AMqgAZjzDMxewGJTysNpVRiOBqcici5IrJNRHaKyG0R7p8pIs+LyFsi8pKITAu7r1tENgY/nnByncod3tpVRo6/jI7CBaz89AnMm5QDx30SPvY3aCqH+0+Hva8O/4nX3A37X4fzfgC5U3pvz5/hXOZs7xp45KNQdCQcew28+wo8chX86Ej45y020Ak1Ie0JzP4CZ3wTTvly5Oec+T444jT490+gfYgMR6DbBlQTjoBjPx7dmlO9NlA75064cS3cuB7O+V/ILoZXfw4PngN3LYCnbofyDa5uoioiBcDFwGxgCpAlIldHuO56EVkrImurqqqG8QLx29ZUSsWfY8GZiKQC9wDnAQuBq0RkYb/Lfgj83hizGLgD+G7YfX5jzNLgx0VOrVO5Q11LB3f/2cbwZ59+Rt/xRkecCp96ATIK4HcXwYaHo3/iQ1vhhe/Ys1SLr+h7X/50Z86clW+AP15hA8GPPQbn/wC+tA0+shLmnAEb/2QDnZ8ugef/x5752vwonPltOPlLgz/3aV+D1mp48/7Br9v0CBwqtcFeqndkP0fhHLsdes0/bFbtQw/C9BXw5q/hvlPhnhXw8g9GntFMbmcCe4wxVcaYTuBvwPv6X2SMuc8Ys9wYs7y4uDj6Z9cJAUq5mpOZsxXATmPMbmNMB/AI9jfJcAuB54Nfvxjh/lEz4+QNbLz8nJEEAoab/7yRSf5dAGTPWHL4RUVz4VPP2ezR4zfA45+DA+sH/weuu9Oe4UrPgQt/YreSwuXPgMbygbcaR+LQO/DQB8GXD//1OGRPtLeneuHIc+BDD8BXdsClv7LBz7/vstWpZ/43nHTL0M8/fQXMPQv+8zNob4p8TacfXrwTphwDCy+Jzc+VkQ/vuQw+/Af48nZbVJFVDC9+xwaZD5wDbz4ArbWxeb3E2wccLyKZYnu2nAFsHckTRfy77bJtzfH8/qVUJE4GZ1OB8LRCWfC2cJuAy4JfXwrkiEiopM4XTPe/JiIj+hfC5/NRU1Pj+r/4xhhqamrw+UbZkHKMuvvFnby8vYqrZzdDei7kTY98YUYBXP1XOP4GW2l4/2lw93E2e1O75/DrX7kLKjbawCw7QlYjbzpgoPFAbH6Q2t3w+4vtgfprHoe8aZGvS8+BJVfarNoXt8InnoGTbo7+dU67Hfy18PqvIt//xn32ZzrrjsMD0ljIKLBbpdeugpvftkUFbQ3wry/CD4+E0rF/isEY8zrwKLAe20YjBbhvuM8z8HuYe7Y1x/v7l1KROFmtGeldvf87zJeBu0Xk48Bq4AAQKkGaYYwpF5EjgBdE5G1jzK4+LyByPXA9wIwZMw57sWnTplFWVsawznKMUT6fj2nTBvjH3MVe2VHFj5/bzqXLpnJky15bRThYQJHqhXO/a3t/lT5ug7QXv2M/pr/Xbl0u+qA9S7b6+3D0FbBwgF31/OD/cw37YcLs0f0gDQfgdxdDd4cNWiYcEd3jcibbj+GYeiwceZ49B7biur6VoP462w9t7lm2wtNp+TPg5C/arF/lZlvtOW25868bB8aYbwHfGs1zDPge1tZgPxpGlIxLOuP1/UupgTgZnJUB4SmMafQrJTfGlAMfBBCRbOAyY0xD2H0YY3aLyEvAMmBXv8ffR/C30eXLlx+WHvN6vcyePcp/NFX0AgFbvRcnFQ1+bnpkI/MmZnPnJYuQu0ph8eXRPTiUvTn24zYQe/tRGxj860vw5K02A5dZBOd/f+DnyA/+7z3aooDmKpsxa6uHa56AiQtG93zROO12+NUp8Nov4dRbe2//94+hrdGeX4snETtKaPLR8X3dJDfge9grd8Hz/w1fPzj8psJKqaTn5L+kbwLzRGS2iKRhGzD22a8QkSIRCa3hduDB4O0FIpIeugY4ESh1cK1qtHY8C9+bHrczQx1dAT738HraO7u59+pjyfQfhPYGmNi/5iQKoezNDa/Bp1+xTVqzJ8Gl99ogbiC50wAZXTsNfx08dCk0lNkD/1OWjfy5hqNkiS1yWHOPXQPYNbz2S7tlOvk98VmHGplQQNbpT+w6lFKOcCw4M8Z0AZ8HnsYehF1pjNkiIneISGif6FRgm4hsByYBdwZvXwCsFZFN2EKB7xljNDhLZjuehY5me0B+BCoa/Nz9wg6u/vXr3PXMNjYfaBj0rOB3n9zK+n31fP9DS5hTnG071gNMGkVQIQIli+Hs78DnXoM5pw9+vScNckpGnjlrb4KHL4fqbXDlwzDzhJE9z0idersNaNf8wn7/4ncBYys6VXILDTzv0pmWSrmRoxMCjDGrgFX9bvtm2NePYg/N9n/cq4Dub4wlB9baz+2NUT+koyvAc1srWbl2P6u3VxEwMHdiNne/uJOfvbCTKXk+zlo4ibMWTua9R0zAm2p/l/jXWxX85j/vcu2Js7hgcYl9ssrN9nM8tgTD5c8YeTuNNb+AsrXw4YfsjMp4m/weW4352r223cimP9piifzDz2+qJKOZM6VcTcc3qdHraoeDwfEuA7VnCPPOwUZWvlnG3zceoLalg5I8H587bS6XHzudGYWZ1LZ08PzWSp4preTPa/fzuzV7yfV5OG3+RI4/opDv/LOUY2bkc/t5YYFY5RbInwm+XId+yAHkT7cNakei8m0omgcLPhDbNQ3HqbfZwoiHPwRpOUP3SVPJwZNuP2vmTClX0uBMjd7BzbbKEOxh8jD+jm721bayp7qF3dXNPL35IJvKGvCmCmcvnMzly6dx8rxiUsOaxk7ISuPy5dO5fPl0/B3dvLKjimdLK3n+nUM8vrGcCVlp3P2RY0jzhO3KV24Z3ZbmSOVNhy2P2S79qcP861S9w04ASKSJC2z/sc2P2pYWmRMSux4VHU8oc6bBmVJupMGZGr0D63q+XL15F0/ufIs91S3srWmloqHvPx7zJ+fwzQsXcsmyqUzIShvyqTPSUjl70WTOXjSZ7oBhw746JmSlMSU/rEKtsw1qdsDCmPcwHlr+DDuAuqmit3ozGt1ddpj6Uec5t7Zonflt247j+M8meiUqWt7QmTPd1lTKjTQ4U6N2cOu/ySSbXJpZs2UPz/gqmVmYyQlzCplVmMWsoixmFWYyszCLvIwRjgICUlOE5bMiZHaq3rENOSctGsVPMUKhgKxh//CCs/q9EOhMfOYM7LrPuXPo61Ty0MyZUq6mwZkasfJ6P3f8o5Sv7H6Dnd5FvC+wlptOnsyt554V34XEolJzpPJn2s/1++xoqGhVb7efkyE4U2OPV6s1lXKz+HUMVYmz+2VoqYnZ03V0Bfjly7s4866XWb99N3NSKjj+lLNJ8eXi626O2etErXKLzSSMtkv/SIRGLA2311koOCucG9v1qPEhlDnT4EwpV9LgzO26u+APl8GqL8fk6dbsquH8n73C9558hxPnFvHPD2YB4Jm+3HbVb4u+lUbMVG62B9tTUuP/2t4MyJoIDcPsdVa13Ta6zch3Zl3K3UKZM22loZQr6bZmsms4YA9rjzTw8Nfas02lj9vnyus7e37bwSbuenYbq7dXMyErjcl5PiblpjMp18ekXB+Tc31MzE0nL8PL/at38/eN5UwryOCBa5ZzxoJJ8PL3AbGd7dNzh9XnLCaMscHZUefH93XD5U8ffiPa6u26palGTjNnSrmaBmfJyBjY87IdQL1nNVzyS1h61cieqzW4nWm64c37e2Ym7qlu4SfPbeeJTeVkpXm49Jip+Du6qWxs452DTazeXk1ze1efp0pLTeELp8/lhtPm4vMGg8UD62yQ4cuzPcai6HMWU82H7M+YiPNmIfkzoOKt6K83xgZn7/mgc2tS7qaZM6VcTYOzZBIIwPanbFB2YC1kTwYEaneP/Dlbqu3nnBJY91vKl9zIT18+wKPry/CmCp8+ZQ6fPuUICiK0tWhu76KysY3KxjaqmtpZOj2fmYVZvRcYYzvcH3mO/T49185njKfQZIBEVGqG5E2Hd/4V/eD3lmo75FwzZ2qkNHOmlKtpcJYMurug9O82KDtUaisAL/wxLPkI/HghtFaP/LmDmbOmFTeT8/yt3PvT/+UxcyYfO34mN5w2h4k5vgEfmp3uIbs4286ujKR+n13b1GPs975cONQw8rWOxKHgyNVEBmf5M2wT3pZDdgt6KD2VmvOcXZdyr1QPSKpmzpRyKQ3OEqmrAzb9Cf79Y6jbA8Xz4dL7bMf2ULf5zKLe7NcI+BsqyQAueCaHX8hsPp/1LJ/5zP8wtSBz9OsPzdOcutx+Ts+J/7Zm5RabFUxkZ/vQLMr6fcMMzjRzpkbBm6GZM6VcSqs1E+nJr8I/vmAr9j78MHx2DSz5cN8xQFlFvefGhqGjK8AD/97Dg8/a7v3HLZzHpLNvYVL7XqbWrInN+g+sB4+vN2sVqtY0JjbPH43KzYnNmoHd1oToiwKqd4A3E3KnObcm5X4en2bOlHIpzZwlSlsjvPVnWPpRuPgeEIl8XWYhVG2L+mmNMax6+yDff/od9ta08quiNro7cvnRVSugawm8die8di/MPWP0P0PZWihZAqnBrv++XFt40NkKaVmDPzYWujvtn82c051/rcHkDzc42277m0VzPk2pgWjmTCnX0n8dEmXzX20Qs/yTAwdmEMycRbetuW5vLZfd+yqf++N6fJ5UfnvtcZw9y0tqVqG9wJMOx30Kdj5r+2yNRncnVGyCqcf23paeaz/Hq9dZzU571iuRlZpgt3MzCuwIp2hoGw0VCx6fBmdKuZQGZ4my4SGYuLD3MP1AMougtRYC3QNesqe6hc88tI7L7l1DWZ2f/7vsaFbddDKnHjURaa22AV7IsddCajq8/svRrf9QqR26HCk4i9e5s56xTQne1gR77iyazFmn316nwZkaLa9PZ2sq5VK6rZkIlaW2P9g53x08awbBwMqAv65vkAW0d3Xzk+d2cP/q3aR5UrjlzCO57pTZZKaF/WdtrYHcsMaz2cVw9OW2EOGM/2czPiNRFioGCAvOfKHgLE6Zs8rNkOKFwiSoesybbs+SDaVmF2C0UlONnifD/oKklHIdzZwlwoaHbFCx+MNDX5sZ3JLsVxSw+UADF/38P9z70i4uWTaVl75yKjedOa9vYAZ2pmZm36CO4z9jt1TX/37kP8OB9XZtBbN6b+vZ1oxTO43KLVB8FHgO79EWd/kzbUZsqGIIrdRUsaKZM6VcS4OzeOtqh02PwPwLIHQWbDCh4CzYTqOrO8DPnt/BJff8h9rWDh78+HJ+ePmSyP3KjLFBXf82E5OPhlknw+v32R5rI3FgrW2hEZ75i3vmbEtybGmCLQro8g9dWVu9AxAonBOXZSkX08yZUq6lwVm8bVtl510u+1h014e2Mlur2XmoicvufZW7nt3O+UeX8MzNp3D6/EkDP7ajBbrbD9sOBeD4G6CxDN75x/B/hrZGWyUZvqUJ9mA8xOfMWWstNB5IouAsrNfZYKq322u9Gc6vSbmbJ10zZ0q5lJ45i7f1D9n+VnNOi+764Jbkvze9wye2pJGVlso9HzmGCxaXDP3YUJVnZoQM3ZHnQMFs21Zj0aVRLj6ofANgYFr/4CyO1ZrJMBkgXHivs8GKPLRSU8WKVzNnSrmVZs7iqX4/7HoBln4EUlKjesi+NptheX3zdk6ZV8TTt5wSXWAGvVts/c+cgX39934a9r9uixOGI3T9lH5BSE/mLA7BWU+lZoLbaISEMmeDtdMIBGz7Dw3OVCx49MyZUm6lwVk8bfwjYGDZR6O6fPOBBs6/53UaTSYXHZnO/f+1fNBZmIdpCQVnA5xtW/pRSMuB14bZVuPAOpgw5/CzbCmpkJYdn8xZ5Wb7c2UPsq0bTxn5NnM42LZmY5ktxNBKTRUL2oRWKdfS4CxeAgHY+AeY/f6+FY4D2F/bysd/8yZ5GV4y8icxL6sNGartRn89mbMB5k76cuGYj8GWv0FjRfTPe2Dd4efNQtJz43PmLFQMMNw/EyflTbfZ0YFopaaKJW1Cq5RraXAWL3tetlmVY/5ryEvrWjq45jdv0NHVzW+vPQ5vTvHIhp+HzpxFKggIWXG9bXD75q+je86GA9BUAdOWR77flwvtDrfSCHTDoa0wMUnOm4UM1Yg21AdNgzMVC94MOyFjkAbVSqmxSYOzeNnwEPjyYf6Fg17W1tnNp36/lrI6P7++5jjmTcoZ8fBzWmtsP7XQQf1IJsy2bT3WPmgrIIcSOm82WObM6W3Nunft9mCyFAOE5E+3Z84G6nVWvd3+PzBYsKxUtDzBIw6aPVPKdTQ4i4fWWtj6T1h8hW0cOYDugOGmRzawfl8dP/nwUlbMDm5HZk4YWXDWUm3PZQ219ff+r9qtyH98YegmqgfW2oBv8tGR70/PcX5bM5nGNoXLn2GLIdrqI99fvcM2zU2mrVg1doXasWhRgFKuo8FZPLz9F9tvbJDeZsYY7vjHFp7eUsn/u2Ah5x8dVpGZWWQDraECp/5aawcuBghXssSOctr6j6GnBhxYbwMzT3rk+325zldrVm4BSYHi+c6+znD1tNMY4NxZ9XYtBlCx05M503YaSrmNBmdOM8b2NitZAiWLB7zsvtW7+d2avXzqpNl84qTZfe/MKoJA5/CDntaa6KYQAEkX45cAACAASURBVJxwoy1WeOq2gWdEBrptj7OBzptBfLY1KzfbatG0TGdfZ7gGa0Trr4fmSj1vpmJHM2dKuZYGZ06r2ASVbw+aNXt84wG+++Q7XLi4hK+dv+DwC0J9yoZbFNBaHV3mDCAlBS79lf1t/NFP2DFT/VVtg47mgc+bQfwyZ8m2pQmD9zqr2Wk/a3CmYiWUvdbMmVKuo8GZ0zY8ZAOeoy+PePeru6r58l828d7ZE/jRFUtISYlwHqlnhNMwz521Rhh6PpjcErj4Hjj4FrzwP4fff2Ct/Tx1iMxZVxt0dQxvrdFqb4a6PcnTfDZcZiF4MyNva2obDRVrHs2cKeVWGpw5qdMPb/0FFlxkm5T2s+1gE5/+/TpmF2Vx338tJ90zwNSAfsPPo9LdBf666DNnIfPPh+WfhFd/bqcZhDuwDnx5MOGIgR8fqgx1qijg0Fb7ORkzZyLBXmd7D7+verstpMifGf91KXfy6pkzpdxKgzMnbf2H7fl1zOFbmv6Obj778Doy0lL5zbUryMvwDvw8YcPPo+av6/vY4Tj7O/aw/WOf6RsQlgWbz6YM8r+NLxScOdTrrHKz/ZyMwRnYrc1I25rVO6BwDqTqOFsVI5o5U8q1NDhz0vrf22kAM0867K7vPbmV3VUt/PjDS5manzH484zkzFnP0PMBpgMMJi0TLnvAHmJ//HO2qKGjxQ4bH+y8GTg//Lxyix05FTrflWzyp0cuCNBKTRVrXu1zppRbaXDmlIYD8O4rsOzqwzJNr+yo4ndr9nLtibM4cW4Uma20TPtb8nDOnA029Dwak98DZ90B25+y0wMqNoHpHvy8GYQNP3doW7N8vV1bsvYKy5tus5bhP393J9Tu1vNmKrZCmTMNzpRyHQ3OnBI6PD/njD43N7R28pW/vMXcidnceu4w+nQNd0pAKMs23DNn4d77aZh7FjzzDdjwsL1tqMxZz7amA5mz5kO2z1q/P9Ok0tNOI2xrs+5dCHRpcKZiK5Q569QzZ0q5jQZnTinfCCkemLiwz83/7/HNVDe38+MrluLzDlAAEElm4TC3NUOZs1EEZyJwyb02G7bxDzbwyC4e/DFObmtufxowcNR5sX/uWInUTqOnUlO3NVUMaeZMKddyNDgTkXNFZJuI7BSR2yLcP1NEnheRt0TkJRGZFnbfNSKyI/hxjZPrdETFRpi4oM+4pic2lfPEpnJuOmMeR0/LG97zZRUNryAgFsEZ2GDskl/ar4fKmkFYtaYDwdm2JyFvRvIWA0DkRrSh4KxQgzMVQ5o5U8q1HAvORCQVuAc4D1gIXCUiC/td9kPg98aYxcAdwHeDj50AfAt4L7AC+JaIFDi11pgzxp7RKlnac9PBhja+8djbLJuRz2dPnTP858wsgpZhnjlLzwVP2vBfq795Z8IVv4dTbx/6Wqe2NTv9trXHUecl73kzgKyJkJrWNzir2g45Jb1/NkrFgg4+V8q1nMycrQB2GmN2G2M6gEeAi/tdsxB4Pvj1i2H3nwM8a4ypNcbUAc8C5zq41thqKLPBUckSAAIBw1ce3URnt+GuK5biSR3BH/tIMmejzZqFW3ixHdo9FE86pKbHfltz98u2n1Myb2mCLf7Im3545kzPm6lYS0m1vfM0c6aU6zgZnE0Fwhs+lQVvC7cJuCz49aVAjogURvlYROR6EVkrImurqqpitvBRq9hoP09ZBsBDr+3llR3VfP2CBcwuyhrZc2YWQmcrdLRGd33LMEY3xZoTI5y2rbKZwJknxvZ5nZA/vffMmTG2x5kGZ8oJ3gzNnCnlQk4GZ5H2nky/778MvF9ENgDvBw4AXVE+FmPMfcaY5caY5cXFQxxUj6eKTSCpMGkRu6qa+e6TWzn1qGI++t5R9OYabiPa1pqRNaCNhfSc2GbOAgHb0mPuGbHZpnVa/ozezFnzIduQV4Mz5QSPTzNnSrmQk8FZGTA97PtpQHn4BcaYcmPMB40xy4CvB29riOaxSa18IxTPpzMlnS/+eSM+byrfv2wxMpqzUsNtRBvrbc3hSM+NbZ+z8g3QXAlHnR+753RS3gxoqbL/aGqlpnKS1wdd7YlehVIqxpwMzt4E5onIbBFJA64Engi/QESKRCS0htuBB4NfPw2cLSIFwUKAs4O3JT9j7LbmlKXc/cJONpU1cOclRzMx1zf0YwcTCrRaa6NbQyKDs1hva25bZTORc8+M3XM6qaedRpkOPB/HRCRfRB4VkXdEZKuInBDzF/Fk6GxNpVzIseDMGNMFfB4bVG0FVhpjtojIHSJyUfCyU4FtIrIdmATcGXxsLfA/2ADvTeCO4G3Jr6kCWqqoy1vI3S/u5NJlU7lgccnon3c425odLfYcSiIzZ7Hc1tz2JMx838hGUSVCfjDpW7/XnjfzZkHulMSuSSXCT4GnjDHzgSXY98HY8vp0tqZSLuToFGZjzCpgVb/bvhn29aPAowM89kF6M2ljR7ktBni+fjLdAcOXz4miwjEaoUArmm3NUI+zhJ05i+G2Zt27cGgLnPO/sXm+eMgLBWf7e2dqJnP7DxVzIpILnAJ8HCBYsd4R8xfSzJlSrqQTAmKtYhNICr/bk8txswqGHmoeLV+eLZuPJnPWGoPRTaMRy23NbU/Zz8neQiNcTomdDlG/Tys1x68jgCrgNyKyQUR+LSIjLNUehGbOlHIlDc5irWIj7flzeftQJxctieFWlkj0I5xC59ISXRAQCIz+ubatguL5MOGI0T9XvKR67DZm9XZo2KfB2fjkAY4B7g0WPLUAkaakjK4dkMenmTOlXEiDs1gr38iO1DmkpgjnHx2Ds2bhoh1+Houh56PhywUMdIxya9NfD3v/M7ayZiH5M2HPavu1VmqOR2VAmTHm9eD3j2KDtT5G3Q7Io5kzpdxIg7NYajoIzQd5vqGEE+cWUZidHtvnjzpzFqO5miOVnmM/j/bc2c7nINA1dlpohMub3ru1q5mzcccYcxDYLyKhQ6dnAKUxfyFtQquUKzlaEDDuVGwC4JXmaVwZyy3NkKwi2/NrKK019syTb5jD1WMlNPy8rRFGs4RtT0JWcXQD15NNqJ2GpIytLVkVSzcCDwdbCe0Gro35K2gTWqVcSYOzWCrfiEHYmXoE5yyaFPvnj3b4eWtwdFOiKgRjMfy8uxN2PAsLP2BnCI41oXYa+TPtoW017hhjNgLLHX0RzZwp5Uq6rRlDgfKNvMsUjj9qBjk+b+xfILPQjgLq7hz8utba3okCiZAeTJeNptfZ3lftzzoWtzShN3MWzbB4pUbK49PgTCkX0uAshjrL1rOpeyYXL3Wo4WhWaErAENmzlurENmztOXM2iuBs25P2H54jTo3FiuIv1OtMiwGUk7wZ9lxmd1eiV6KUiiENzmKluYr01oNsT5nLafMnOvMa0c7XTOTQcxj9tqYxtoXGEadCWuxbQ8VF/gxYdCksuDjRK1Fu5glumWs7DaVcRYOzGOk4sB6ArFnH4vM6dEYq2hFOoTNniRJeEDASh7ba0UdjsYVGSEoqXP5bmH5colei3MwbbHKt7TSUchUNzmJk79uvArB4+cnOvUg0mbPuLtsfLJFnztKybJXiSDNn24ITv448N3ZrUsqNNHOmlCtpcBYjLe+uYy8lHL9wtnMv0pM5G+TMmb8OMInNnInYc2cj7XO27UnbPiNncmzXpZTbhIIzzZwp5SoanMVAS3sXxU1bachfiDfVwT/SjAJABs+c9Qw9T2BwBrZicyTbmk2VcGDt2N7SVCpevJo5U8qNNDiLgZc3bWOqVJM/x+HzRSmptgpzsDNniR56HjLS4efbQ4POx2gLDaXiyaNnzpRyIw3OYmDrulcAmLbwBOdfLLMousxZooOzkW5rbnvSVjpOXBj7NSnlNpo5U8qVNDgbpfrWDgLBkUopU5Y6/4KZhbbJ7EB6grMEFgSArdhsaxjeYzpaYfeLNmuWqOkGSo0locxZV3ti16GUiikNzkbpyc0HWchuOnJmQEa+8y+YVTj4tmZovFMim9DCyLY1962x3c7nne3MmpRym1DmTOdrKuUqGpyN0hMby1nm2Yd3+jHxecFotjXTc8GTHp/1DCQ9d/gFAQ377WcdeaRUdHpaaeiZM6XcRIOzUahsbKN0z16mmINIPLY0wbbT8NdCIBD5/tYEj24KCZ05Myb6xzQdtJ+zHRgar5Qb9TSh1cyZUm6iwdko/POtChbJu/abkiXxedHMIjCBYD+zCFprEn/eDOy2ZqBzeL/RN1VAVjGkOjA0Xik30syZUq6kwdkoPLGpnDPyKuw3JXHMnMHA585aEjy6KWQkI5yaDmrjWaWGw6NnzpRyIw3ORmhvTQub9tfz/pwDkDcjfluJocBroHNnrbWJHXoe4suzn4dTFNBYDjklzqxHKTfSzJlSrqTB2Qj9Y1M5ALM6dsCUOG1pwuCZM2OS68wZDC84azqowZlSw5GSAqnpmjlTymU0OBuh1durOWGKB0/9nvhtaULvebJI8zU7W+1v0Mlw5my425rdndBSpcGZUsPl9WnmTCmX0eBsBIwxbK1o5MyCYHVhXIOzYFasJUJw1pIko5vAFgRA9Jmz5kOA0TNnSg2XJ0MzZ0q5jAZnI1BW56epvYtl3n32hni10QDbvyw9N/K2ZrKMboLebc1oM2ehNhqaOVNqeLw+nRCglMtocDYCW8ptwDGrcwfkTov/AfzMwsgFAaGxTslQEBDa1ox2vmaTPcOnmTOlhsmTobM1lXKZqIIzEfmriFwgIuMnmOvqGPCu0opGUgTy60rj198sXFbRAJmzJNrWTB/mtmYoc5Y7xZn1KOVWXh906pkzpdwk2mDrXuAjwA4R+Z6IzHdwTYlXvRPunAT3nQZv3H9Yw9etFY0sLBRSanfGd0szJLMo8pmzZNrWTPWAN2sY25oVIKnJUcyg1FjiydCCAKVcJqrgzBjznDHmo8AxwLvAsyLyqohcKyLua+des9N24W8+BKu+DD88Cv5yLex8DgLdlJY3cmZBFWDiWwwQMtDw85ZqSPH09hhLtPSc4WXOcibb1gBKqeh5fVoQoJTLeKK9UEQKgauBjwEbgIeBk4BrgFOdWFzC+INnt655wp6Z2vgwvP0X2PI3AjlTuKr5OE4qyrbXJGJbMzT83BgQ6b29tcZmzcJvSyRf7jCCswo9b6bUSHh80HUo0atQSsVQVMGZiPwNmA88BHzAGBOcWcSfRWStU4tLmNA2ZuYEKJxjty7P/g5se5KGV3/DZxufILXM2MrCnAQM6c4qsnMr2xv7ZslCwVmySM8dXrXmhCOcXY9SbuTRzJlSbhNt5uxuY8wLke4wxiyP4XqSQ2stSAqkhwU+nnRYdAmP1S3hl7v+wwtnV5I9KUHBRHgj2mQOzny50NYQ3bWN5TDzRGfXo5QbefXMmVJuE+0BnwUikh/6RkQKROQGh9aUeP468OVHPP9UWtFIIHsy2ad/CRZdmoDFETZfs19RQLIMPQ9Jz4mulUanH9rqdVtTqZHQzJlSrhNtcHadMaY+9I0xpg64zpklJQF/3YDzKbdWNLKgJCfOC+onKxiA9S8KaK1Jjh5nIdFua2oDWqVGzpuhTWiVcplog7MUkd5T5iKSCqQ5s6Qk4K+FjILDbu7oCrCjspmFU3ITsKgwoW3N8Ea0ge5gUJlEmTNfXnQFAT3BmWbOlBo2j882oTUm0StRSsVItMHZ08BKETlDRE4H/gQ8NdSDRORcEdkmIjtF5LYI988QkRdFZIOIvCUi5wdvnyUifhHZGPz45XB+qFHz10UMznZVNdPRHWBhSYKDs1B2LDxz5q8DTHL1CUvPtcPYuzsHv64pWF+imTOlhs/rs61/hvp7ppQaM6ItCLgV+DTwWUCAZ4BfD/aAYHbtHuAsoAx4U0SeMMaUhl32DWClMeZeEVkIrAJmBe/bZYxJQBMxoLUOihccdvPWCpsFSnhwlpZlG0+GZ856GtBG3o5NiNB8zfamwdcVCs5yNThTatg8GfZzlx887t3QUGo8iSo4M8YEsFMC7h3Gc68AdhpjdgOIyCPAxUB4cGaAUKSTB5QP4/mdM0DmrLS8kXRPCrOLshKwqH6yinoDMugN1JJqWzNshNNQwZnHZ4swlFLD4/XZz51tydOAWik1KtHO1pwnIo+KSKmI7A59DPGwqcD+sO/LgreF+zZwtYiUYbNmN4bdNzu43fmyiJwczTpjorsTOiJnekorGpk/OQdPahJ0se8//DwUqCVbQQAMXRQQmg6QLM1zlRpLPMHgTIefK+Ua0UYZv8FmzbqA04DfYxvSDibSv7T9T6xeBfzWGDMNOB94KDhcvQKYYYxZBnwR+KOIHLaXKCLXi8haEVlbVVUV5Y8yhFAD2n6ZM2NMsFIzwVuaIf2HnyfT0POQnm3NaIIz3dJUyUlEbhKRXLEeEJH1InJ2otfVwxOWOVNKuUK0wVmGMeZ5QIwxe40x3wZOH+IxZcD0sO+ncfi25SeBlQDGmDWADygyxrQbY2qCt68DdgFH9n8BY8x9xpjlxpjlxcXFUf4oQxggODvY2EZda2fiKzVDMvttaybT0POQnm3NIXqd6egmldw+YYxpBM4GioFrge8ldklhvGFnzpRSrhBtcNYWzGjtEJHPi8ilwMQhHvMmME9EZotIGnAl8ES/a/YBZwCIyAJscFYlIsXBggJE5AhgHjDUNmpstAbnavYLzkrLk6QYICSzsG8T2pYaSMuxkwySRWjCwmDbmsZAYwXkTInPmpQavtAuwPnAb4wxm4i8M5AYmjlTynWiDc5uBjKBLwDHYgegXzPYA4wxXcDnsW04tmKrMreIyB0iclHwsi8B14nIJmx7jo8bYwxwCvBW8PZHgc8YY2qH96ON0ACZs1Cl5vxkCc6yCqGzpbczeGtNb3PaZBFeEDCQ9ib7c2jmTCWvdSLyDDY4e1pEcoBAgtfUSzNnSrnOkNWawQzWFcaYrwDN2JR+VIwxq7AH/cNv+2bY16XAYQMVjTF/Bf4a7evEVPjQ8zClFY3MLMwkOz3a7iMOC29Emz/dnjlLpi1NiO7MmU4HUMnvk8BSYLcxplVEJjCM90HH9RQE6JQApdxiyMyZMaYbODZ8QoCr+Qfe1kyaLU04vBFta01yNaAF+49Ginfwbc2eBrSaOVNJ6wRgmzGmXkSuxvZnbEjwmnqFMmc6X1Mp14h2W3MD8LiIfExEPhj6cHJhCeOvA0ntbQMBNLd3sbe2NXkqNSEsc1bT+znZMmcidmtTM2dqbLsXaBWRJcBXgb3YivXk0JM50zNnSrlFtHt0E4Aa+lZoGuBvMV9RorUG52qGJQq3HWzEmCQqBoDImbNkO3MGQw8/bwoW8GrmTCWvLmOMEZGLgZ8aYx4QkUHP3MaVZs6Ucp1oJwQkz/kKp0WYDtBTqZksbTSgN0vWUg0drfYwcLJlzsCeOxuslUbTQRvApWfHb01KDU+TiNwOfAw4OXgO15vgNfUKVWhr5kwp14gqOBOR33B4A1mMMZ+I+YoSzV8XoRigibwMLyV5vgQtKgJfnj3P1VqTnA1oQ3x5Q2xrao8zlfQ+DHwE2+/soIjMAH6Q4DX18mjmTCm3ifbM2T+BfwU/nsfOw2x2alEJ5a89PHNWYYsBkqomQsQGY63VYQ1ok6wgAKLY1jyowZlKasaYg8DDQJ6IXAi0GWOS6MxZOiCaOVPKRaIKzowxfw37eBi4AniPs0tLEH99n+CsO2DYdrAxubY0Q0KNaFuScDpAyJAFARVaDKCSmohcAbwBXI5973tdRD6U2FWFEbFFAZo5U8o1Rtq0ax4wI5YLSRqttZDRu625p7qFts5AclVqhmT1y5wl09DzkPScgYMzY3SuphoLvg4cZ4w5BCAixcBz2AbZycHr08yZUi4S7ZmzJvqeOTsI3OrIihKpq912qw/LnJVWJNnYpnCZRVCxKezM2YTBr0+E9FxbEGBMnwpYwAbC3R0anKlklxIKzIJqiP5ISHx4MjQ4U8pFoq3WzHF6IUnBX28/Z4YFZ+WNeFOFuROTsJowq6g3cyap4MtP9IoO58sFE4CO5t6JASHagFaNDU+JyNPYEXNgCwRWDXJ9j2Bl51rggDHmQofWZzNnOltTKdeI6rc/EblURPLCvs8XkUucW1aCRJgOsLWikXkTc0jzJNcvyoDNnLU12K3BzMLDM1PJIBSQRSoK0Aa0agwIjq67D1gMLAHuM8ZEu3NwE3a2sLM0c6aUq0QbcXzLGNMzrsQYUw98y5klJVCEoeelFY3Jed4MepvOVm9PzvNm0DtpIVKvM82cqTEiWAz1RWPMLcaYx6J5jIhMAy4Afu3s6ghmzrQgQCm3iLYgIFIQlyQTwGOoNZQ5s2e3qpraqWpqT85KTehtnVG1HUoWJ3YtA/EFE66RigJ6MmcanKnkE+Gsbc9dgDHGDPXG8BPsuCfnj4Vo5kwpV4k2c7ZWRO4SkTkicoSI/BhY5+TCEqJf5mxrMhcDQG+2rL0hOdtoQG/mLOK2Zrldd6jDuVJJxBiTY4zJjfCRM1RgFuyHdsgYM+j7pIhcLyJrRWRtVVXVyBfrSdfMmVIuEm1wdiPQAfwZWAn4gc85taiECQVnwarHpK7UhL5NZ5M2OAsmDQbKnOl5M+VOJwIXici7wCPA6SLyh/4XGWPuM8YsN8YsLy4uHvmreTVzppSbRFut2QLc5vBaEs9fCykeSLOVmaXljUzNzyAvM3nG6PURHpAl65kzX+jMWaTgTEc3KXcyxtwO3A4gIqcCXzbGXO3YC2oTWqVcJdpqzWdFJD/s+4Jgabm7hIaeB6setyZzMQAEM3zBCs2kzZwNtq2po5uUigltQquUq0S7rVkUrNAEwBhTB0x0ZkkJFDYdoK2zm11VzSwsSeIWbympvZWlyRqcpWUDcnjmLNANzZW6ralczxjzkqM9zsAWBGjmTCnXiDY4C4hIz7gmEZlF5CqmsS2UOQO2HWwiYEjeSs2Q0HZmsgZnKSnBEU79Wmk0H7LNaTU4U2r0vD474UQp5QrRtsP4OvBvEXk5+P0pwPXOLCmB/PWQPx0Ir9TMG+wRiZdZBGxP3uAM7NZm/23Nnh5nGpwpNWqeDOjyRx6TppQac6LKnBljngKWA9uwFZtfwlZsuou/tidzVlrRSHa6h2kFGQle1BBCjWiTtSAAbFFA/21N7XGmVOx4ffazZs+UcoVoB59/CjuGZBqwETgeWAOc7tzSEiBsW7O0vJEFJTmkpCT5b6GZSb6tCcHMWUPf2zRzplTseIK/RHb5ewM1pdSYFe2Zs5uA44C9xpjTgGXAKDomJqHONuhshYwCAgHDOwebkre/WbiZJ8LsU5K7kWukM2dNB0FSIGsUvZ2UUlbo778OP1fKFaI9c9ZmjGkTEUQk3Rjzjogc5ejK4i1sOsD+ulaa27uSu41GyOLL7Ucy8+VC7a6+tzWVQ/YkSHXfFDCl4s4bljlTSo150f7LWBbsc/Z34FkRqQPKnVtWAoRNB9hX2wrAEcXZCVyQi0QsCNAeZ0rFjCe4lamZM6VcIdoJAZcGv/y2iLwI5AFPObaqRPCHhp4XUNvYAUBRdloCF+Qi6TmRCwLyZ0S+Xik1PJo5U8pVhr2nZIx5eeirxqCwbc3qchucFWYl8TmuscSXC90dtpIsdDamqQKmr0jsupRyC82cKeUq0RYEuF9rKHM2gZrmdjwpQm6GnoeKifRgr7jQ1mZXO7TWaKWmUrHSkznT4EwpN9DgLCQsc1bb0sGErDREmznGRv/h582V9rMGZ0rFRihzpsGZUq6gwVmIvw5S0yAti+rmDgqzdUszZtKD80lDvc4atceZUjEVypzpfE2lXEGDs5DQdAARalvaKczSYoCYSQ9lzoK9znoa0Gq1plIxoZkzpVxFg7OQsOkANS0dFGqlZuz039bsGd2kmTOlYkIzZ0q5igZnIf56yJgAQE2zPXOmYiSUOQsVBDRV2C3kzAmJW5NSbhKqgtbMmVKuoMFZSKvd1mzr7Ka5vYsiPXMWO4dtawYb0GrBhVKxEZqtqa00lHIFDc5C/HWQaSs1AT1zFkuHbWuW65amUrGU6rWzarUJrVKuoMFZSLAgIBSc6bZmDKV67W/2oWpNHd2kVGyJ2L9jmjlTyhUcDc5E5FwR2SYiO0Xktgj3zxCRF0Vkg4i8JSLnh913e/Bx20TkHCfXSaffntXIKKC6uR1AW2nEmi+3b0GAZs6Uii2vTzNnSrmEYy3wRSQVuAc4CygD3hSRJ4wxpWGXfQNYaYy5V0QWAquAWcGvrwQWAVOA50TkSGNMtyOL7WlAO0G3NZ2SnmPPnLU32yBNM2dKxZYnw07fUEqNeU5mzlYAO40xu40xHcAjwMX9rjFA8EASeUB58OuLgUeMMe3GmD3AzuDzOaO1d+h5TXMwONNWGrGVnmurNXumA0xJ7HqUchuvT1tpKOUSTgZnU4H9Yd+XBW8L923gahEpw2bNbhzGY2MnlDnLnEB1SztpqSlkp+tczZgKbWs2BuNvzZwpFVueDG2loZRLOBmcReqTYPp9fxXwW2PMNOB84CERSYnysYjI9SKyVkTWVlVVjXyl/t7MWW2zbUCrczVjLJQ50wa0SjlDM2dKuYaTwVkZMD3s+2n0bluGfBJYCWCMWQP4gKIoH4sx5j5jzHJjzPLi4uKRrzRs6LlOB3BIeq49c6ajm5RyhsenmTOlXMLJ4OxNYJ6IzBaRNOwB/yf6XbMPOANARBZgg7Oq4HVXiki6iMwG5gFvOLbSsIKAmpYOJmRppWbMhbY1mw6CN6t3GLpSKjY8mjlTyi0cO1hljOkSkc8DTwOpwIPGmC0icgew1hjzBPAl4H4RuQW7bflxY4wBtojISqAU6AI+51ilJtiCgNR08GZQ09zOnKIsx15q3ErPhY5maCyD3BKdDqBUrHk1c6aUWzh66t0Yswp70D/8tm+GfV0KnDjAY+8E7nRyfT38dXbOowi1LTpX0xGhTFn1Dj1vppQTXTO0hAAAHe9JREFUPBmaOVPKJXRCANjgLKOA1o4uWju6tQGtE0IjnGp26nkzpZygmTOlXEODM+gJznp6nGnmLPZCw8+7OzQ4U8oJ2kpDKdfQ4Ax6grOe6QBarRl7ocwZ6LamUk7w+nS2plIuocEZ2IKAjAJqWnSupmPSNThTylGeDOhuh0Ag0StRSo2SBmfG9BQE6LamgzQ4U8pZXp/9rFubSo15Gpx1ttrfNoMNaEG3NR3RZ1tTz5wpFXOeDPtZgzOlxjwNzsKmA9S2dODzppCZpnM1Yy5dgzOlHOUJHsfQdhpKjXkahYRNB6hubqdQpwM4w5sBkmr7nXkzEr0apdzHq5kzpdxCg7PW3qHnNc06V9MxInZrU8+bKeUMT/DMmWbOlBrzdFszlDnLnEBtS4cWAzgpPVe3NJVyimbOlHINzZz5wzNnBzlykg7kdsyK6yB3SqJXoZQ7aeZMKdfQ4CyYOTO+fGpaOijSbU3nvO/GRK9AKffqyZy1J3YdSqlR021Nfx14MmgxabR3BfTMmVJqbAplzro0c6bUWKfBWWtorqb9bXOCVmsqpcaiUOZMRzgpNeZpcBaaDqANaJVSY5lmzpRyDQ3O/LU9bTRARzcppcaonoIAzZwpNdZpcOavg4x8anXouVJqLPNq5kwpt9DgzF8XnA6gmTOl1Bjm0TNnSrnF+A7OjLETAoJzNbPSUvF5UxO9KqWUGr5UD6R4NHOmlAuM7+CsowUCnbYgoLldtzSVUmObJ0MzZ0q5wPgOzsKnA7R0MEG3NJVSMSAi00XkRRHZKiJbROSmuLyw16fjm5RygfE9ISA0VzNYrTkl35fY9Sil3KIL+JIxZr2I5ADrRORZY0ypo6/qydDgTCkXGOeZs1BwNoGalnbNnCmlYsIYU2GMWR/8ugnYCkx1/IW9Pp2tqZQLjO/grNVua5qMfGpbOvTMmVIq5kRkFrAMeN3xF/PotqZSbjC+g7Ng5qwpJZfObqNtNJRSMSUi2cBfgZuNMY0R7r9eRNaKyNqqqqrRv6BHM2dKucE4D85s5qy2OxPQ0U1KqdgRES82MHvYGPO3SNcYY+4zxiw3xiwvLi4e/YtqQYBSrjDOg7N68GZS3SYAFOrQc6VUDIiIAA8AW40xd8XthT0ZmjlTygXGeXDWdzqAFgQopWLkROBjwOkisjH4cb7jr6qZM6VcYXy30gibDgBQpAUBSqkYMMb8G5C4v7A2oVXKFTRzlllATbMdel6Q5U3wgpRSahS8Ph3fpJQLjPPgrLZnOkCOz0O6R+dqKqXGME8GdLUnehVKqVEa58FZXU9wpm00lFJjnjahVcoVxm9wZkxPQUBtiw49V0q5gCcDAp0Q6E70SpRSozB+g7P2Jgh09czV1EpNpdSY5w3OB9bsmVJj2vgNzkJzNTNtK40ibUCrlBrrPMHgTNtpKDWmjePgzE4HCPjyqWvt0Aa0Sqmxz6OZM6XcYBwHZzZz1pKSQ3fA6LamUmrs82bYz5o5U2pMczQ4E5FzRWSbiOwUkdsi3P/jsO7Z20WkPuy+7rD7noj54oLBWa3JAXSuplLKBTRzppQrODYhQERSgXuAs4Ay4E0RecIYUxq6xhhzS9j1NwLLwp7Cb4xZ6tT6aLXbmjWhoee6ramUGus0c6aUKziZOVsB7DTG7DbGdACPABcPcv1VwJ8cXE9ffpukq+yyb2aaOVNKjXlaEKCUKzgZnE0F9od9Xxa87TAiMhOYDbwQdrNPRNaKyGsicskAj7s+eM3aqqqq4a3OXwtp2VQHs//ahFYpNeaFMmc6X1OpMc3J4CzS0F8zwLVXAo8aY8I7J84wxiwHPgL8RETmHPZkxtxnjFlujFleXFw8vNUFG9D2ztXU4EwpNcb1ZM70zJlSY5mTwVkZMD3s+2lA+QDXXkm/LU1jTHnw827gJfqeRxs9fx1k5FPb0kF+phdv6vgtXFVKuYRmzpRyBScjkjeBeSIyW0TSsAHYYVWXInIUUACsCbutQETSg18XAScCpf0fOyqttTodQCnlLp5gYZNmzpQa0xyr1jTGdInI54GngVTgQWPMFhG5A1hrjAkFalcBjxhjwrc8FwC/EpEANoD8XniVZ0z46yBvKjV17RRppaZSyg08mjlTyg0cC84AjDGrgFX9bvtmv++/HeFxrwJHO7k2/MHM2f4O5hRnO/pSSikVF149c6aUG4zPg1aBQG9BQEuHttFQSrmDZs6UcoXxGZx1NIEJhM3V1OBMKeUCKSmQmqaZM6XGuPEZnAWnA7Sk5mIMFGbrmTOllEt4MjRzptQYNz6Ds+BczUbRuZpKqbFlw746PvuHdXR0BSJf4PXphAClxrhxHZzVBuxcTW2loZQaKw41tfPk5oP86JltkS/waHCm1Fg3roOz6oCt0izSbU2l1BhxzqLJfPS9M/jV6t38e0f14Rd4M6BTz5wpNZaN6+DsUIetbNLMmVJqLPnGBQuZOzGbL67cSG1LR987NXOm1Jg3PoOzYEFARbsPESjI1OBMKTV2ZKSl8tMrl1Lf2slXH32LPj28PT7NnCk1xo3P4MxfB+m5VPkDFGSmkZoSaUa7Ukolr0VT8rj1vPk8t7WSP7y+r/cOLQhQaswbv8FZRj41zdrjTCk1dl37vlm8/8hivvPPUrZXNtkbtZWGUmPeOA3OaiFjArUtOvRcKTV2paQIP7x8CTk+D1/40wbaOruDmTPd1lRqLBunwVkdZBRQ3dKulZpKqTGtOCedH3xoCe8cbOL/nnpHM2dKucD4DM4u+jmccye1OldTKeUCp82fyMffN4vf/OddDrQYPXOm1Bg3PoOziQvoLFpAfWunbmsqpVzhtvPmM39yDi/taiKg1ZpKjWnjMzgD6oK9gXSuplLKDXzeVH521TIauz2YTj+BgBn6QUqppDRug7OaUHCmmTOllEscOSmHE46aRioB/vefb9sCAaXUmDN+g7NmDc6UUu6zZNYkAB55dRtn/OhlVr1d0bdJrVIq6f3/9u48TorqWuD47/Q2+8AMqyKbgIrGgMLHXYNBcIkRfG5AJMbkPWJcEjV5z+VlMUoSjVuiT40bCSq4S+QBcQGXgHFDBAUEBAQFZ2BggNmgp5eTP6qGGcaZYQa67eru8/18+tPd1VXVp4vuy5lzb93K3uSsNgxgJwQYYzKKBJ3L0k2deCRFuQEun7aICQ+/y8ry6hRH1oIdG+HJ8fD5O6mOxBhPyd7kbHflzMacGWMySCAXgGEH5jHrqpO4ZcwRLC+r4qx75nPTzGXsqIukOEBXPAYvTIKVc2DahVC+NNURGeMZWZucVdbW4/cJnfKCqQ7FGGMSx62cEd1FwO9j4vH9eOMXIxh/TG8ee3sdI+54nenvfk4s1ScMzL8T1i+Ab/8KQgXwxHmwbV1qYzLGI7I2OdtaG6YkP4TPrqtpjMkkbuWs6cXPSwpCTB57JLOuOplBPYq4ccbHfOee+fztrc8o35GCOdHWvw1v/AGOvBBO/jlMfMGZm+3xc6Gm4uuPpz0+mw8zfgK1W1IdickCWZucbampp6uNNzPGZJqgm5y1MBHt4QcW8/Sk47h3/FHEVbnp/5dz3B/mcf4D/+LRBZ/x5favYX60ukp4/j+hc184+y4Qge6D4XvPQlUZTDsPdlUlP46OqC6HZy+BJdPhkZFQsSrVEZkMl7XJmV1X0xiTkQKN3ZotERG+O+RAXrnmW8y99hSuHXUINeEot8xazgm3vsa597/FI/PXsmFbXeJjU4WZV0HNJjh/CuQUNb7W+xi46HHYtAyemuCdS1DF4/D3n0B9HYz9C9TXwqOnOZU0Y5IkkOoAUmVrTZgjD+qc6jCMMSaxGipn7UhuBnYv4qcji/jpyEGsqajhpaXlzP6ojMmzP2Hy7E/o37WAAd0KGdDdve9WyIBuBXTO38c/bBc+CitmwejJ0Ovor74+aBSMuR9mTIIX/gsu+Bv4/Pv2Xonyzv2w5jU4+24YOh76ngDTL3S6YM+5B4ZOSG18JiNlb3JWW29znBljMs/uylnHuigHdCvkilMHcsWpA1m3pZZ/LC3now3bWVNRwz9XVVAfi+9et2thiIPdZO3QHoUc2rOYw3oWUdJWm7ppGbx0IwwYCcdd0fp6Qy6Cuq3w8g0w++dOUiQpGhtctgTm3gSHnQ3DLnWWlfSFH74Mz3zfqahtWwcjbkhdjCYjZWVyFo7GqN4VteTMGJN5OlA5a02/rgX8ZMSA3c+jsTgbtu1kTUUNaytqWVNRw5qKGv6xtIwn32ucmqNHcQ6H9ixmcM8iDnVv/boUkC9h5NlLIbcTnPsX8O1lRM3xl0NtBSy4Cwq7w6k37vNnQRWWvwgVK+GkqyHQzumT6mvhuR9BQVc45949k6+8znDx8zDranjzNqhcC2Pua/++TWbauQ1iEec7u5+yMjmrtOtqGmMyVcPZmh2snLW5S7+Pfl0L6Ne1gJGDG5erKpurw6wor2ZleRUryqpZUV7NX9ds3aPSdlvoES7yreSGgptZN30tJQVfUJIfoiQ/ROf8IEW5AfJCAQpCfvJDAfJDfgqOvIYDtpVT8OZtxHwh/Cf9DPwdnPpoy2qY83NY+4bz/NOX4cLHoVOvvW/70g2wdTV8/0XIL/3q6/4gnPN/UHowzLsZdmyAcdNbXtdkvtVz4cUr4YAhMOHp/d5dViZnDRPQ2gkBxpiME9j/yll7iQg9inPpUZzLtw7ptnt5JBZn3ZZaVpRXk7NqJqOXvcbrXSewpfhEIrX1rCivZntdhO119bQ13ZqfM7k3uJqzXr+Fja89wOO+c3glNJpAbj4FOQEKQgEKcpyETsQpksVV8cd2MWrrNE7b9hQRCfFi16uoDXRhYtltxO49kTeG3E79QSdQUhCiND9ESUGQkvwQ+SE/IuJU2hZNhZOugYO/1dYBcKYCKennTLPxyGkw/IdOYhzZ6fwbROrcx+59IAeOuhgGnb73CqLxvnANvPorWDgFuh0GI65PyG6zMzlzK2c2lYYxJuME92HMmSqEq2FnpTPVxc5KqNsGRT2hz/Hg79h/FUG/j0E9ihgUqoQ5v4dewzn1h/dwarPKVzyuVO2KUFsfoy4cpa4+Rm19lLpwjLqIs6ws/CAzy9/kqM//yvXVU7gy+jzz/P/BnODZVNTnsaUmTG19FFXwiXBi7D1+Wv8IB+hmXg2O4OGcS9kRKSWyK84c/T231/+R0Qsn8ft3vseU2BnAnmPF+gYqmRm4jg0ykMsXnkBgyRvkBv3kBHzkBPy7k8F8t8pXkOMnLzSEfsMe4tuLryH3lf91Ppv4ifryiPhzifpyiPhyiEguhZEtFK2YRV2ngewafjnFx0wgkJPXoeNrPOLzd2DGZc64w+OvdCZUbhhWsJ+yMjmrdK+raZUzY0zG2VvlrLocPnoGPn3FGddVV+mMlYm3clmnvBI45Ew47Dsw4NsQym/9vVVh6xqni2f1XFi3wOn+O//RFrskfT6hc36Izm3s0nEwcCmsf5vCBXcz5tO/Mib0LAy/1Dm5oPgA2LYeXrreuRxUt8PgrCmM6n8yo/bYzwhiO88j9vxl/Hr141xxaBWLh97M1rCfyrp6doXrOffj28mrjfOPQZMZ5u9OOBInHI0RjsbZWR/jy+0R6uqdRNK5Rd3qX5AgfyKXenYSItrCf68Bn+DTCGfKO/x422wOn3ctm+bezIzQOXzYfSxdunanT2k+3YtyKMoNUpwboDjP6fYtzgtSGArYxOleEA3D67+Dt+6Bzr3hB7Oh34kJfYusTM52X1fTxpwZYzKNiJOgNa2cRXbBytmw+ElYMw80Dj2/CV0HQV6pM06q4T6/i/M4rwQqVsCK2c62S6Y7Z4IOHOkkaoec4awfroF1851k7NNXYft65z27DIRhP3Cmmijpl5jP1vd451a+FBbcDW/fB+8+CINGw+p5zmc/7bdw3OUQaPmPb39eJ/wTpsFbd9Nl3i2MrF0DFz0BpQPgn3dA9Ycw9gF+MfTMdoWkqoSjcWrdyh84lcOAXwj6fQT9QsDn3IsIsbhStmMUn2+9ljdWzaPfyke5bMdj1H35LM9tPI37d42mnC4IcUqoobtsp5tspzvb6ebbTq9AFUW+CO8Ej+XD0DB8gSAh970a3jPkd7pLI3ElGosTjSmRuHsfixONK/G4OusGfE5VMOhslxPw714W8AvxOChKXJ3cW1HnXpWmPdINKaOINNYiBUJ+H8V5QTrlBRvvcwN0arIsN+gn5G88Rp5W9hHM+DFsXg5HXwKn/27P+foSRFRTfH21BBk+fLguXLiwXeve9tIKHpm/llWTz/T+F8EY0yoR+UBVh6c6jpaIyBnAnwE/8Iiq3trW+h1pw/bq1r5w5AXObcl0WDoDwjuguBcMGQdDxjuJWXvFIrD+LSdRWzEbqjaC+J2Z/StWOlW3YIEzPmvgSGe6jNL+ifksban8DP51j1MJHHAqnHErdDqo/duvnuuckQlw8rUw97dwxFg479Gvd2qMsiXwr3th6QuoCLG8bvjrKhCNfmXVsC+fOEJevJbt/i68VXg6b+SfzkZfT6IxpT4Wpz4ad3J0v4+gT3YnbQGfOMv8gk+EaEwJR2PUx+JuhdDZNhyNUR+NE4krPnG6iwU38RLn0PiaJGENWURD8tbwGCAcjVO1M0I4Gm/+UVoUchPGoF/ce+e5kzj6vrIsFGhMMJs+D/n9jY8DPkLuZ/b7nHufT/CLOJ/PXRZwj1VDMu33NSa9oUg1Jcum0vm9u4jllrB5xO3U9h2J4oxzbBjvWJwbpHfpXkvBQNvtV1YmZ//z3BLeXFXBuzeeluSojDHJ5NXkTET8wCpgFLABeB8Yr6rLW9smocnZnYdBzWbQGATzYfB3nYSs/yn7P6mrKpQtdpK0L96FA4bCwNOgz3HpOZVE5Wfw9ETY9DF06gOXzXemykiFbevh/YedrubCHs6tqAcU9nSmZyjq6VwkPhaBVS/Bosdh9atOJbTvSXD0RBh8TttdzymyKxKjameEql0RduxsvFXtjO5OButj6txH40Rijfdh9/HuW2zPdcJNljW8HmvrTJO9Ug6WMob5VnG0fMow3yoO8W0EYFbsOH4ZuZTttFwtO/MbPXng4mHtepe22q+s7dYsLUjDRsQYky6OAVar6loAEXkKGAO0mpwl1ICRTvfikHFw+JjEdruIwIFHObdMUNoffvSKU7k67KzUJWbgTHA7evLe1/MHnYR78Heh6ktYPB0+fMLpbpvz33Dk+dDnhMbqnwggTaqB0r7KoCqgze6bvtawO3d/4mvcd9PHQK5722MGsDwgt3kS1Z6kqunnarbMFVOIxpxu3Ug8TizeUOFyumibVrtUFY0rwW2ryN/0AQWbFxGs3w5AJFjMttKhfFJ6HptLhxPtOpzfSmP3rc+tJjpDAYWeneyEgH22tdYuem6MSapewBdNnm8Ajm2+kohMAiYB9OnTJ3HvPva+xO0rG4TyYcR1qY5i3xQfCKf8Ak661ul6/vAJZ2zhwimpjiyl/O6tw2WYrofCEWdD72Oh97EEuwyiu89Hd2DwXjdOnKxMzv48bijR/Sp5GmNMm1oqS3yl0VHVh4CHwOnWTHZQJoP5fND/ZOf2nTucs3KbV75gz2XtGlcnzSpvzapxDfvSuPs43uQ94u18n2avt7X+7opdK1W8/dG5j2cmEU5qcra3AbEicjdwqvs0H+iuqp3d1y4Bfum+NllVpyYqrr5dChK1K2OMackGoHeT5wcBX6YoFpNtcoqScgah+fokLTlzB8TeR5MBsSIys+mAWFW9psn6VwFHuY9Lgd8Aw3HS4w/cbbclK15jjEmg94FBItIf2AiMAyakNiRjTLpI5rUjdg+IVdV6oGFAbGvGA0+6j08HXlXVSjchexU4I4mxGmNMwqhqFLgSeBn4BHhGVZelNipjTLpIZrdmuwbEAohIX6A/8Fob27bjSrXGGOMNqjoHmJPqOIwx6SeZlbN2DYh1jQOeU9VYR7YVkUkislBEFlZUVOxjmMYYY4wx3pHM5KwjA2LH0dil2e5tVfUhVR2uqsO7deu2n+EaY4wxxqReMpOz3QNiRSSEk4DNbL6SiBwKlABvN1n8MjBaREpEpAQY7S4zxhhjjMloSRtzpqpREWkYEOsHpqjqMhG5GVioqg2J2njgKW1yHSlVrRSRW3ASPICbVbUyWbEaY4wxxnhFUuc5a2lArKr+utnzm1rZdgqQ3VMcG2OMMSbrJLNb0xhjjDHGdJAlZ8YYY4wxHiKaqGtSpZiIVADrO7BJV2BLksJJtHSJNV3iBIs1GVIRZ19VzYhTtTvYhqXLdwIs1mRIlzjBYm1Lq+1XxiRnHSUiC1V1eKrjaI90iTVd4gSLNRnSJc5MkE7H2mJNvHSJEyzWfWXdmsYYY4wxHmLJmTHGGGOMh2RzcvZQqgPogHSJNV3iBIs1GdIlzkyQTsfaYk28dIkTLNZ9krVjzowxxhhjvCibK2fGGGOMMZ6TdcmZiJwhIitFZLWIXJ/qeNoiIutE5GMRWSwiC1MdT1MiMkVENovI0ibLSkXkVRH51L0vSWWMDVqJ9SYR2ege28UiclYqY3Rj6i0ir4vIJyKyTER+5i733HFtI1bPHddMY21YYqRLG5Yu7RekTxuWDu1XVnVriogfWAWMAjbgXLtzvKouT2lgrRCRdcBwVfXcHDEicgpQAzymqt9wl/0RqFTVW93/NEpU9bpUxunG1VKsNwE1qnpHKmNrSkQOAA5Q1UUiUgR8AIwFfoDHjmsbsV6Ix45rJrE2LHHSpQ1Ll/YL0qcNS4f2K9sqZ8cAq1V1rarWA08BY1IcU1pS1X8CzS9GPwaY6j6eivNlT7lWYvUcVS1T1UXu42rgE6AXHjyubcRqksvasARJlzYsXdovSJ82LB3ar2xLznoBXzR5vgGP/YM0o8ArIvKBiExKdTDt0ENVy8D58gPdUxzP3lwpIh+53QYp775oSkT6AUcB7+Lx49osVvDwcc0A1oYll6d/a814+neWLm2YV9uvbEvOpIVlXu7XPVFVjwbOBK5wy9smMR4ABgBDgTLgztSG00hECoHngatVtSrV8bSlhVg9e1wzhLVhBjz+O0uXNszL7Ve2JWcbgN5Nnh8EfJmiWPZKVb907zcDM3C6NLxsk9uX39CnvznF8bRKVTepakxV48DDeOTYikgQp7GYpqovuIs9eVxbitWrxzWDWBuWXJ78rTXn5d9ZurRhXm+/si05ex8YJCL9RSQEjANmpjimFolIgTtQEREpAEYDS9veKuVmApe4jy8BXkxhLG1qaChc5+KBYysiAjwKfKKqdzV5yXPHtbVYvXhcM4y1Ycnlud9aS7z6O0uXNiwd2q+sOlsTwD019k+AH5iiqr9LcUgtEpGDcf7SBAgA070Uq4g8CYwAugKbgN8AfweeAfoAnwMXqGrKB7K2EusInNK1AuuAHzeMiUgVETkJmA98DMTdxTfijIXw1HFtI9bxeOy4ZhprwxIjXdqwdGm/IH3asHRov7IuOTPGGGOM8bJs69Y0xhhjjPE0S86MMcYYYzzEkjNjjDHGGA+x5MwYY4wxxkMsOTPGGGOM8RBLzkxWEJERIjIr1XEYY0xHWfuVfSw5M8YYY4zxEEvOjKeIyMUi8p6ILBaRB0XELyI1InKniCwSkXki0s1dd6iIvONepHZGw0VqRWSgiMwVkSXuNgPc3ReKyHMiskJEprmzRBtjTEJY+2USxZIz4xkiMhi4COdiyUOBGPA9oABY5F5A+U2cGbIBHgOuU9Vv4sz03LB8GnCfqg4BTsC5gC3AUcDVwOHAwcCJSf9QxpisYO2XSaRAqgMwpomRwDDgffePwjycC+TGgafddZ4AXhCRTkBnVX3TXT4VeNa9ll8vVZ0BoKq7ANz9vaeqG9zni4F+wILkfyxjTBaw9sskjCVnxksEmKqqN+yxUORXzdZr65pjbZX6w00ex7DvvzEmcaz9Mglj3ZrGS+YB54tIdwARKRWRvjjf0/PddSYAC1R1B7BNRE52l08E3lTVKmCDiIx195EjIvlf66cwxmQja79MwljmbTxDVZeLyC+BV0TEB0SAK4Ba4AgR+QDYgTOuA+AS4C9u47UWuNRdPhF4UERudvdxwdf4MYwxWcjaL5NIotpWhdWY1BORGlUtTHUcxhjTUdZ+mX1h3ZrGGGOMMR5ilTNjjDHGGA+xypkxxhhjjIdYcmaMMcYY4yGWnBljjDHGeIglZ8YYY4wxHmLJmTHGGGOMh1hyZowxxhjjIf8GLuKHK21gxJQAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"resnet152V2_model.load_weights('../working/model.weights.best.hdf5')\n\nclass_indices = train_generator.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\n\ntest_generator_new = test_gen.flow_from_directory(\n    directory=TEST_DIR,\n    target_size=(64, 64),\n    batch_size=1,\n    class_mode=None,\n    color_mode='rgb',\n    shuffle=False,\n    seed=69\n)\n\npredictions = resnet152V2_model.predict_generator(test_generator_new, steps=len(test_generator_new.filenames))\npredicted_classes = np.argmax(np.rint(predictions), axis=1)\ntrue_classes = test_generator_new.classes\n\nprf, conf_mat = display_results(true_classes, predicted_classes, class_indices.values())\nprf","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:06:10.938175Z","iopub.execute_input":"2022-08-21T13:06:10.938470Z","iopub.status.idle":"2022-08-21T13:09:21.557192Z","shell.execute_reply.started":"2022-08-21T13:06:10.938440Z","shell.execute_reply":"2022-08-21T13:09:21.556549Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Found 5400 images belonging to 10 classes.\nAccuracy: 0.960925925925926\nGlobal F2 Score: 0.9609259259259261\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"                      Precision    Recall   F-Score  Support\nAnnualCrop             0.946625  0.960191  0.953360    628.0\nForest                 0.970636  0.986733  0.978618    603.0\nHerbaceousVegetation   0.968696  0.957045  0.962835    582.0\nHighway                0.947368  0.936803  0.942056    538.0\nIndustrial             0.969828  0.914634  0.941423    492.0\nPasture                0.972603  0.939153  0.955585    378.0\nPermanentCrop          0.963597  0.937500  0.950370    480.0\nResidential            0.923300  0.998435  0.959398    639.0\nRiver                  0.964000  0.962076  0.963037    501.0\nSeaLake                0.998201  0.992844  0.995516    559.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F-Score</th>\n      <th>Support</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AnnualCrop</th>\n      <td>0.946625</td>\n      <td>0.960191</td>\n      <td>0.953360</td>\n      <td>628.0</td>\n    </tr>\n    <tr>\n      <th>Forest</th>\n      <td>0.970636</td>\n      <td>0.986733</td>\n      <td>0.978618</td>\n      <td>603.0</td>\n    </tr>\n    <tr>\n      <th>HerbaceousVegetation</th>\n      <td>0.968696</td>\n      <td>0.957045</td>\n      <td>0.962835</td>\n      <td>582.0</td>\n    </tr>\n    <tr>\n      <th>Highway</th>\n      <td>0.947368</td>\n      <td>0.936803</td>\n      <td>0.942056</td>\n      <td>538.0</td>\n    </tr>\n    <tr>\n      <th>Industrial</th>\n      <td>0.969828</td>\n      <td>0.914634</td>\n      <td>0.941423</td>\n      <td>492.0</td>\n    </tr>\n    <tr>\n      <th>Pasture</th>\n      <td>0.972603</td>\n      <td>0.939153</td>\n      <td>0.955585</td>\n      <td>378.0</td>\n    </tr>\n    <tr>\n      <th>PermanentCrop</th>\n      <td>0.963597</td>\n      <td>0.937500</td>\n      <td>0.950370</td>\n      <td>480.0</td>\n    </tr>\n    <tr>\n      <th>Residential</th>\n      <td>0.923300</td>\n      <td>0.998435</td>\n      <td>0.959398</td>\n      <td>639.0</td>\n    </tr>\n    <tr>\n      <th>River</th>\n      <td>0.964000</td>\n      <td>0.962076</td>\n      <td>0.963037</td>\n      <td>501.0</td>\n    </tr>\n    <tr>\n      <th>SeaLake</th>\n      <td>0.998201</td>\n      <td>0.992844</td>\n      <td>0.995516</td>\n      <td>559.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Save the model and the weights\nresnet152V2_model.save('../working/ResNet152V2_eurosat.h5')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T13:11:29.007931Z","iopub.execute_input":"2022-08-21T13:11:29.008203Z","iopub.status.idle":"2022-08-21T13:11:32.784705Z","shell.execute_reply.started":"2022-08-21T13:11:29.008171Z","shell.execute_reply":"2022-08-21T13:11:32.783661Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## VGG16 Model","metadata":{}},{"cell_type":"code","source":"vgg16_model = compile_model('VGG16', INPUT_SHAPE, NUM_CLASSES, Adam(lr=1e-2), fine_tune=None)\nvgg16_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator.reset()\ntest_generator.reset()\n\nN_STEPS = train_generator.samples//BATCH_SIZE\nN_VAL_STEPS = test_generator.samples//BATCH_SIZE\nN_EPOCHS = 100\n\n# model callbacks\ncheckpoint = ModelCheckpoint(filepath='../working/model.weights.best.hdf5',\n                        monitor='val_categorical_accuracy',\n                        save_best_only=True,\n                        verbose=1)\n\nearly_stop = EarlyStopping(monitor='val_categorical_accuracy',\n                           patience=10,\n                           restore_best_weights=True,\n                           mode='max')\n\nreduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.5,\n                              patience=3, min_lr=0.00001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator.reset()\n# First Pretraining the dense layer\nvgg16_history = vgg16_model.fit_generator(train_generator,\n                             steps_per_epoch=N_STEPS,\n                             epochs=50,\n                             callbacks=[early_stop, checkpoint],\n                             validation_data=test_generator,\n                             validation_steps=N_VAL_STEPS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# re-train whole network end2end \nvgg16_model = compile_model('VGG16', INPUT_SHAPE, NUM_CLASSES, Adam(lr=1e-4), fine_tune=0)\n\nvgg16_model.load_weights('../working/model.weights.best.hdf5')\n\ntrain_generator.reset()\ntest_generator.reset()\n\nvgg16_history = vgg16_model.fit_generator(train_generator,\n                             steps_per_epoch=N_STEPS,\n                             epochs=N_EPOCHS,\n                             callbacks=[early_stop, checkpoint, reduce_lr],\n                             validation_data=test_generator,\n                             validation_steps=N_VAL_STEPS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(vgg16_history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model.load_weights('../working/model.weights.best.hdf5')\n\nclass_indices = train_generator.class_indices\nclass_indices = dict((v,k) for k,v in class_indices.items())\n\ntest_generator_new = test_gen.flow_from_directory(\n    directory=TEST_DIR,\n    target_size=(64, 64),\n    batch_size=1,\n    class_mode=None,\n    color_mode='rgb',\n    shuffle=False,\n    seed=69\n)\n\npredictions = vgg16_model.predict_generator(test_generator_new, steps=len(test_generator_new.filenames))\npredicted_classes = np.argmax(np.rint(predictions), axis=1)\ntrue_classes = test_generator_new.classes\n\nprf, conf_mat = display_results(true_classes, predicted_classes, class_indices.values())\nprf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model and the weights\nvgg16_model.save('../working/vgg16_eurosat.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_predictions(true_classes, predictions, test_generator_new, class_indices)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}