{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-26T02:11:30.525867Z","iopub.execute_input":"2022-08-26T02:11:30.526436Z","iopub.status.idle":"2022-08-26T02:11:34.963362Z","shell.execute_reply.started":"2022-08-26T02:11:30.526339Z","shell.execute_reply":"2022-08-26T02:11:34.959415Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam\n\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nimport tensorflow as tf\n\nimport cv2\nimport os\n\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-08-26T02:23:03.557653Z","iopub.execute_input":"2022-08-26T02:23:03.558141Z","iopub.status.idle":"2022-08-26T02:23:03.566927Z","shell.execute_reply.started":"2022-08-26T02:23:03.558107Z","shell.execute_reply":"2022-08-26T02:23:03.564993Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"labels = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\nnelabels = ['Residential', 'NonResidential']\nimg_size = 64\n#data_dir = '../input/eurosat-dataset/EuroSAT'\ndef get_data(data_dir, str1):\n    data = [] \n    if str1 == 'train':\n        thresh = 300\n    else:\n        thresh = 150\n    for label in labels: \n        path = os.path.join(data_dir, label)\n        if label == 'Industrial' or label == 'Residential':\n            class_num = 0\n            #thresh = 1000\n        else:\n            class_num = 1\n        #class_num = labels.index(label)\n        counter = 0\n        for img in os.listdir(path):\n            counter = counter + 1\n            if counter > thresh:\n                break\n            try:\n                img_arr = cv2.imread(os.path.join(path, img))[...,::-1] #convert BGR to RGB format\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                if resized_arr.shape[0] != 64:\n                    continue\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T02:23:08.638625Z","iopub.execute_input":"2022-08-26T02:23:08.639126Z","iopub.status.idle":"2022-08-26T02:23:08.653525Z","shell.execute_reply.started":"2022-08-26T02:23:08.639042Z","shell.execute_reply":"2022-08-26T02:23:08.651491Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2022-08-26T03:59:53.038218Z","iopub.execute_input":"2022-08-26T03:59:53.038858Z","iopub.status.idle":"2022-08-26T03:59:53.045980Z","shell.execute_reply.started":"2022-08-26T03:59:53.038822Z","shell.execute_reply":"2022-08-26T03:59:53.044135Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"#Now we can easily fetch our train and validation data.\ntrain = get_data('../input/eurosat-dataset/EuroSAT', 'train')\nval = get_data('../input/eurosat-dataset/EuroSAT', 'val')","metadata":{"execution":{"iopub.status.busy":"2022-08-26T02:37:09.929765Z","iopub.execute_input":"2022-08-26T02:37:09.930265Z","iopub.status.idle":"2022-08-26T02:37:15.746729Z","shell.execute_reply.started":"2022-08-26T02:37:09.930231Z","shell.execute_reply":"2022-08-26T02:37:15.745103Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"x_train = []\ny_train = []\nx_val = []\ny_val = []\n\nfor feature, label in train:\n  x_train.append(feature)\n  y_train.append(label)\n\nfor feature, label in val:\n  x_val.append(feature)\n  y_val.append(label)\n\n# Normalize the data\nx_train = np.array(x_train) / 255\nx_val = np.array(x_val) / 255\n\nx_train.reshape(-1, img_size, img_size, 1)\ny_train = np.array(y_train)\n\nx_val.reshape(-1, img_size, img_size, 1)\ny_val = np.array(y_val)\n\nprint(len(x_train))\nprint(len(y_train))","metadata":{"execution":{"iopub.status.busy":"2022-08-26T02:37:17.799340Z","iopub.execute_input":"2022-08-26T02:37:17.799800Z","iopub.status.idle":"2022-08-26T02:37:18.057614Z","shell.execute_reply.started":"2022-08-26T02:37:17.799764Z","shell.execute_reply":"2022-08-26T02:37:18.055647Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.2, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip = True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(x_train)","metadata":{"execution":{"iopub.status.busy":"2022-08-26T02:37:22.715124Z","iopub.execute_input":"2022-08-26T02:37:22.716218Z","iopub.status.idle":"2022-08-26T02:37:22.865874Z","shell.execute_reply.started":"2022-08-26T02:37:22.716164Z","shell.execute_reply":"2022-08-26T02:37:22.864350Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(64,64,3)))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\n\nmodel.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPool2D())\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dense(2, activation=\"softmax\"))\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-26T03:56:53.917751Z","iopub.execute_input":"2022-08-26T03:56:53.918264Z","iopub.status.idle":"2022-08-26T03:56:54.004440Z","shell.execute_reply.started":"2022-08-26T03:56:53.918213Z","shell.execute_reply":"2022-08-26T03:56:54.002690Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"opt = Adam(lr=0.001)\nmodel.compile(optimizer = opt , loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) , metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-08-26T02:24:12.171072Z","iopub.execute_input":"2022-08-26T02:24:12.171529Z","iopub.status.idle":"2022-08-26T02:24:12.186437Z","shell.execute_reply.started":"2022-08-26T02:24:12.171495Z","shell.execute_reply":"2022-08-26T02:24:12.184941Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"#testImage = cv2.imread(\"../input/bangalore/bangalore00.jpg\")\nfiles = os.listdir(\"../input/bangalore-segment/\")\ntestArr = []\nfor file in files:\n    print(\"IN\")\n    if not os.path.exists(os.path.join(\"../input/bangalore-segment/\",file)):\n        continue\n    \n    testImage = cv2.imread(file)\n    testImage = cv2.resize(testImage, (64, 64))\n    testArr.append(testImage)\n#testImage = cv2.resize(testImage, (64, 64))\n#val_acc = history.history['val_accuracy']\n#print(val_acc)\n#acc = history.history['accuracy']\n#print(acc)\nmodel.save('../working/base_classification.h5')\nx_val = testArr\nx_val = np.array(x_val) / 255\nx_val.reshape(-1, img_size, img_size, 1)\npredictions = model.predict(x_val)\npredictions = predictions.reshape(1,-1)[0]\nprint(len(x_val), len(y_val))\n#print(classification_report(y_val, predictions, target_names = ['Res (Class 0)','NonRes (Class 1)']))\nprint(predictions)\nif predictions[0] > predictions[1] :\n    print('Residential')\nelse:\n    print('Non - Residential')","metadata":{"execution":{"iopub.status.busy":"2022-08-26T04:06:47.212050Z","iopub.execute_input":"2022-08-26T04:06:47.212540Z","iopub.status.idle":"2022-08-26T04:06:47.248673Z","shell.execute_reply.started":"2022-08-26T04:06:47.212506Z","shell.execute_reply":"2022-08-26T04:06:47.246797Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train,y_train,epochs = 50, validation_data = (x_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-08-26T02:41:47.417593Z","iopub.execute_input":"2022-08-26T02:41:47.418011Z","iopub.status.idle":"2022-08-26T02:42:28.857104Z","shell.execute_reply.started":"2022-08-26T02:41:47.417978Z","shell.execute_reply":"2022-08-26T02:42:28.855469Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}